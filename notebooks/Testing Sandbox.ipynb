{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "polished-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import firestore\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "teams = {'HomeTeam':'Boston Celtics', 'AwayTeam':'Detroit Pistons', 'Model':'automl_regression'}\n",
    "\n",
    "df = pd.DataFrame(teams, index=[0])\n",
    "\n",
    "model = df['Model'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "standing-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "\n",
    "inputs = client.query('''\n",
    "    SELECT\n",
    "      input\n",
    "    FROM\n",
    "      ML.FEATURE_INFO(MODEL `nba.%s`)\n",
    "''' % (model)).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "going-morris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>incoming_is_win_streak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incoming_wma_10_bench_plus_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incoming_wma_10_efg_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incoming_wma_10_ft_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incoming_wma_10_off_rtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>incoming_wma_10_opponent_bench_plus_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incoming_wma_10_opponent_efg_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>incoming_wma_10_opponent_ft_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>incoming_wma_10_opponent_off_rtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incoming_wma_10_opponent_tov_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>incoming_wma_10_opponnent_starter_minutes_play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>incoming_wma_10_pace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>incoming_wma_10_starter_minutes_played_proportion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incoming_wma_10_tov_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_home_team</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input\n",
       "0                              incoming_is_win_streak\n",
       "1                    incoming_wma_10_bench_plus_minus\n",
       "2                             incoming_wma_10_efg_pct\n",
       "3                             incoming_wma_10_ft_rate\n",
       "4                             incoming_wma_10_off_rtg\n",
       "5           incoming_wma_10_opponent_bench_plus_minus\n",
       "6                    incoming_wma_10_opponent_efg_pct\n",
       "7                    incoming_wma_10_opponent_ft_rate\n",
       "8                    incoming_wma_10_opponent_off_rtg\n",
       "9                    incoming_wma_10_opponent_tov_pct\n",
       "10  incoming_wma_10_opponnent_starter_minutes_play...\n",
       "11                               incoming_wma_10_pace\n",
       "12  incoming_wma_10_starter_minutes_played_proportion\n",
       "13                            incoming_wma_10_tov_pct\n",
       "14                                       is_home_team"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "unexpected-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = firestore.Client()\n",
    "\n",
    "home_team_data = db.collection('team_model_data').document(df['HomeTeam'][0]).get().to_dict()\n",
    "away_team_data = db.collection('team_model_data').document(df['AwayTeam'][0]).get().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "asian-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wma_10_opponent_bench_plus_minus': 0.8545454545454545,\n",
       " 'wma_10_starter_minutes_played_proportion': 0.6255297371675052,\n",
       " 'streak_counter_is_win': 4,\n",
       " 'wma_10_off_rtg': 121.73818181818181,\n",
       " 'wma_10_opponnent_starter_minutes_played_proportion': 0.6348266359991303,\n",
       " 'wma_10_opponent_ft_rate': 0.2048727272727273,\n",
       " 'wma_10_ft_rate': 0.24576363636363635,\n",
       " 'wma_10_tov_pct': 11.516363636363637,\n",
       " 'wma_10_pace': 95.96363636363637,\n",
       " 'wma_10_opponent_off_rtg': 120.3509090909091,\n",
       " 'wma_10_efg_pct': 0.5697454545454546,\n",
       " 'wma_10_opponent_efg_pct': 0.5599454545454545,\n",
       " 'wma_10_opponent_tov_pct': 10.994545454545456,\n",
       " 'season': 2021,\n",
       " 'game_date': DatetimeWithNanoseconds(2021, 3, 4, 0, 0, tzinfo=<UTC>),\n",
       " 'wma_10_bench_plus_minus': -2.9272727272727272}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bright-devices",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wma_10_opponent_bench_plus_minus': -17.545454545454547,\n",
       " 'season': 2021,\n",
       " 'wma_10_off_rtg': 112.00545454545455,\n",
       " 'wma_10_starter_minutes_played_proportion': 0.5988811190767316,\n",
       " 'streak_counter_is_win': -1,\n",
       " 'wma_10_pace': 95.77454545454546,\n",
       " 'wma_10_opponent_off_rtg': 114.65454545454546,\n",
       " 'wma_10_opponent_tov_pct': 11.156363636363636,\n",
       " 'wma_10_bench_plus_minus': 6.036363636363636,\n",
       " 'game_date': DatetimeWithNanoseconds(2021, 3, 4, 0, 0, tzinfo=<UTC>),\n",
       " 'wma_10_ft_rate': 0.19163636363636363,\n",
       " 'wma_10_efg_pct': 0.5419090909090909,\n",
       " 'wma_10_opponent_ft_rate': 0.22289090909090908,\n",
       " 'wma_10_opponent_efg_pct': 0.5352545454545454,\n",
       " 'wma_10_tov_pct': 12.341818181818182,\n",
       " 'wma_10_opponnent_starter_minutes_played_proportion': 0.6610975265223425}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "productive-charles",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-274-c03b4156a048>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-274-c03b4156a048>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for key in home_team_data.keys():\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for key in home_team_data.keys():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "arbitrary-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 3, 11, 5, 41, 47, 861755, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now(timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "derived-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rest_days_difference' in inputs.values:\n",
    "    home_rest = (datetime.now(timezone.utc) - home_team_data['game_date']).days\n",
    "    away_rest = (datetime.now(timezone.utc) - away_team_data['game_date']).days\n",
    "    rest_days_difference = home_rest - away_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "sublime-indian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_days_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "collaborative-bracket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incoming_is_win_streak\n",
      "incoming_wma_10_bench_plus_minus\n",
      "incoming_wma_10_efg_pct\n",
      "incoming_wma_10_ft_rate\n",
      "incoming_wma_10_off_rtg\n",
      "incoming_wma_10_opponent_bench_plus_minus\n",
      "incoming_wma_10_opponent_efg_pct\n",
      "incoming_wma_10_opponent_ft_rate\n",
      "incoming_wma_10_opponent_off_rtg\n",
      "incoming_wma_10_opponent_tov_pct\n",
      "incoming_wma_10_opponnent_starter_minutes_played_proportion\n",
      "incoming_wma_10_pace\n",
      "incoming_wma_10_starter_minutes_played_proportion\n",
      "incoming_wma_10_tov_pct\n",
      "is_home_team\n"
     ]
    }
   ],
   "source": [
    "for column in inputs.input:\n",
    "    print (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "controversial-darkness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>incoming_is_win_streak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incoming_wma_10_bench_plus_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incoming_wma_10_efg_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incoming_wma_10_ft_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>incoming_wma_10_off_rtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>incoming_wma_10_opponent_bench_plus_minus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>incoming_wma_10_opponent_efg_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>incoming_wma_10_opponent_ft_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>incoming_wma_10_opponent_off_rtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incoming_wma_10_opponent_tov_pct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>incoming_wma_10_opponnent_starter_minutes_play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>incoming_wma_10_pace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>incoming_wma_10_starter_minutes_played_proportion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>incoming_wma_10_tov_pct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input\n",
       "0                              incoming_is_win_streak\n",
       "1                    incoming_wma_10_bench_plus_minus\n",
       "2                             incoming_wma_10_efg_pct\n",
       "3                             incoming_wma_10_ft_rate\n",
       "4                             incoming_wma_10_off_rtg\n",
       "5           incoming_wma_10_opponent_bench_plus_minus\n",
       "6                    incoming_wma_10_opponent_efg_pct\n",
       "7                    incoming_wma_10_opponent_ft_rate\n",
       "8                    incoming_wma_10_opponent_off_rtg\n",
       "9                    incoming_wma_10_opponent_tov_pct\n",
       "10  incoming_wma_10_opponnent_starter_minutes_play...\n",
       "11                               incoming_wma_10_pace\n",
       "12  incoming_wma_10_starter_minutes_played_proportion\n",
       "13                            incoming_wma_10_tov_pct"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[inputs['input'] != 'is_home_team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "general-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'SELECT predicted_spread FROM ML.PREDICT(MODEL `nba.{model}`, (SELECT '\n",
    "\n",
    "for column in inputs.input:\n",
    "    key = column[9:]\n",
    "    if column == 'is_home_team':\n",
    "        query = query + '1 as is_home_team,'\n",
    "    elif column == 'rest_days_difference':\n",
    "        home_rest = (datetime.now(timezone.utc) - home_team_data['game_date']).days\n",
    "        away_rest = (datetime.now(timezone.utc) - away_team_data['game_date']).days\n",
    "        rest_days_difference = home_rest - away_rest\n",
    "        query = query + f'{rest_days_difference} as {column},'\n",
    "    elif column == 'incoming_is_win_streak':\n",
    "        query = query + f'{home_team_data[\"streak_counter_is_win\"]} as {column},'\n",
    "    elif (column == 'opponent_incoming_is_win_streak') | (column == 'incoming_is_win_streak_opponent'):\n",
    "        query = query + f'{away_team_data[\"streak_counter_is_win\"]} as {column},'\n",
    "    elif column[:12] == 'incoming_wma':\n",
    "        if column.split('_')[3] == 'opponent':\n",
    "            query = query + f'{away_team_data[key]} as {column},'\n",
    "        else:\n",
    "            query = query + f'{away_team_data[key]} as {column},'\n",
    "    else:\n",
    "        print(f'Error: Model input column {column} not in team data in firestore or not in logic in App Engine. Please try a different model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "entitled-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_query = query[:-1] + '))'\n",
    "\n",
    "game = client.query('''\n",
    "%s\n",
    "''' % (bq_query)).to_dataframe()\n",
    "\n",
    "pointspread = round(game['predicted_spread'][0],1)\n",
    "\n",
    "if pointspread > 0:\n",
    "    winner = df['HomeTeam'][0]\n",
    "    loser = df['AwayTeam'][0]\n",
    "else:\n",
    "    winner = df['AwayTeam'][0]\n",
    "    loser = df['HomeTeam'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "dental-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict the Boston Celtics will beat the Detroit Pistons by 1.3 points using the automl_regression model!'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'I predict the {winner} will beat the {loser} by {abs(pointspread)} points using the {model} model!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-count",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "blind-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GCP_PROJECT'] = 'nba-predictions-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "printable-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project='nba-predictions-dev')\n",
    "\n",
    "dataset_id = 'nba'\n",
    "\n",
    "models = client.list_models(dataset_id) \n",
    "\n",
    "model_names = [model.model_id for model in models]\n",
    "\n",
    "# print(\"Models contained in '{}':\".format(dataset_id))\n",
    "# for model in models:\n",
    "#     full_model_id = \"{}.{}.{}\".format(\n",
    "#         model.project, model.dataset_id, model.model_id\n",
    "#     )\n",
    "#     friendly_name = model.friendly_name\n",
    "#     print(\"{}: friendly_name='{}'\".format(full_model_id, friendly_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "european-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [model.model_id for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "olive-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOOSTED_TREE_CLASSIFIER',\n",
       " 'BOOSTED_TREE_CLASSIFIER_ALL_VARIABLES',\n",
       " 'BOOSTED_TREE_CLASSIFIER_ALL_VARIABLES_DIFFERENCES',\n",
       " 'automl_classification',\n",
       " 'automl_regression',\n",
       " 'baseline_linear_model']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "lined-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "for model in models:\n",
    "    model_names.append(model.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "solid-seattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nba-predictions-dev.nba.BOOSTED_TREE_CLASSIFIER',\n",
       " 'nba-predictions-dev.nba.BOOSTED_TREE_CLASSIFIER_ALL_VARIABLES',\n",
       " 'nba-predictions-dev.nba.BOOSTED_TREE_CLASSIFIER_ALL_VARIABLES_DIFFERENCES',\n",
       " 'nba-predictions-dev.nba.automl_classification',\n",
       " 'nba-predictions-dev.nba.automl_regression',\n",
       " 'nba-predictions-dev.nba.baseline_linear_model']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "american-baking",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Iterator has already started', <google.api_core.page_iterator.HTTPIterator object at 0x000001FB97255E80>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-e10f30e24fc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34mf'{model.project}.{model.dataset_id}.{model.model_id}'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\environments\\nba-predictions\\.venv\\lib\\site-packages\\google\\api_core\\page_iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iterator has already started\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ('Iterator has already started', <google.api_core.page_iterator.HTTPIterator object at 0x000001FB97255E80>)"
     ]
    }
   ],
   "source": [
    "model_names = [f'{model.project}.{model.dataset_id}.{model.model_id}' for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "pharmaceutical-newcastle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got model 'nba-predictions-dev.nba.BOOSTED_TREE_CLASSIFIER' with friendly_name 'None'.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "#client = bigquery.Client()\n",
    "\n",
    "# TODO(developer): Set model_id to the ID of the model to fetch.\n",
    "model_id = 'nba-predictions-dev.nba.BOOSTED_TREE_CLASSIFIER'\n",
    "\n",
    "model = client.get_model(model_id)  # Make an API request.\n",
    "\n",
    "full_model_id = \"{}.{}.{}\".format(model.project, model.dataset_id, model.model_id)\n",
    "friendly_name = model.friendly_name\n",
    "print(\n",
    "    \"Got model '{}' with friendly_name '{}'.\".format(full_model_id, friendly_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "subtle-conditioning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(reference=ModelReference(project_id='nba-predictions-dev', dataset_id='nba', model_id='BOOSTED_TREE_CLASSIFIER'))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this function locally after initial data load since it will take more memory than google cloud functions allows\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import firestore\n",
    "import os\n",
    "\n",
    "## TO DO: Replace your Project ID and change the table names if you chose a different dataset name than 'nba' ##\n",
    "\n",
    "os.environ['GCP_PROJECT'] = 'nba-predictions-test'\n",
    "my_project_id = os.environ.get('GCP_PROJECT')\n",
    "client = bigquery.Client(project=my_project_id)\n",
    "raw_game_data_table = f'{my_project_id}.nba.raw_basketballreference_game'\n",
    "raw_player_data_table = f'{my_project_id}.nba.raw_basketballreference_playerbox'\n",
    "games_to_load_to_model_view = f'{my_project_id}.nba.games_to_load_to_model'\n",
    "model_table_name = f'{my_project_id}.nba.model_game'\n",
    "\n",
    "# Enter columns you want to generate linearly weighted moving average calculations for and number of periods to use\n",
    "wma_columns = [\n",
    "    'pace','efg_pct', 'tov_pct', 'ft_rate', 'off_rtg',\n",
    "    'opponent_efg_pct', 'opponent_tov_pct', 'opponent_ft_rate',\n",
    "    'opponent_off_rtg', 'starter_minutes_played_proportion',\n",
    "    'bench_plus_minus', 'opponnent_starter_minutes_played_proportion',\n",
    "    'opponent_bench_plus_minus']\n",
    "W = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "reverse-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(x):\n",
    "    sp = int(x.split(':')[0]) * 60 + int(x.split(':')[1])\n",
    "    return sp\n",
    "\n",
    "def switch_key(key):\n",
    "    new_key = key[:-1] + ('h' if key[-1] == 'a' else 'a')\n",
    "    return new_key\n",
    "\n",
    "def generate_streak_info(data,column):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate streak data\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate streak info\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_streak_counter:\n",
    "        The original dataframe with a new column\n",
    "        `streak_counter_[column]` containing integers with \n",
    "        counts for each streak.\n",
    "    \"\"\"\n",
    "    \n",
    "    data['start_of_streak'] = data[column].ne(data[column].shift())\n",
    "    data['streak_id'] = data.start_of_streak.cumsum()\n",
    "    data[f'streak_counter_{column}'] = data.groupby('streak_id').cumcount() + 1\n",
    "    data_with_streak_counter = data.drop(columns = ['start_of_streak','streak_id'] )\n",
    "    return data_with_streak_counter\n",
    "\n",
    "def create_linear_weighted_moving_average(data,column,weight):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate weighted moving average.\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate weighted moving average info.\n",
    "      Column must be ready to be converted to float data type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_moving_average:\n",
    "        The original dataframe with a new column\n",
    "        `wma_[W]_[column]` containing float values with weighted moving average\n",
    "        values for the provided value with a weight of W.\n",
    "    \"\"\"  \n",
    "    data_with_moving_average = data.copy()\n",
    "    data_with_moving_average[column] = data_with_moving_average[column].astype(float)\n",
    "    weights = np.arange(1,weight+1)\n",
    "    data_with_moving_average[f'wma_{weight}_{column}'] = data_with_moving_average[column].rolling(weight).apply(lambda col: np.dot(col, weights)/weights.sum(), raw=True)\n",
    "    return data_with_moving_average\n",
    "\n",
    "## Load tables to dataframe\n",
    "game_bq = client.query('''\n",
    "SELECT game_date, visitor_team_name, visitor_pts, home_team_name, home_pts, games.game_key, \n",
    "    a_ff_pace, a_ff_efg_pct, a_ff_tov_pct, a_ff_orb_pct, a_ff_ft_rate, a_ff_off_rtg, \n",
    "    h_ff_pace, h_ff_efg_pct, h_ff_tov_pct,h_ff_orb_pct, h_ff_ft_rate, h_ff_off_rtg\n",
    "FROM `%s` as games\n",
    "''' % (raw_game_data_table)).to_dataframe()\n",
    "\n",
    "if game_bq.empty:\n",
    "    print('Function ended early. No new data to load.')\n",
    "\n",
    "player_bq = client.query('''\n",
    "SELECT players.game_key, game_date, h_or_a, mp, plus_minus, starter_flag\n",
    "FROM `%s` as players\n",
    "WHERE mp is not NULL\n",
    "''' % (raw_player_data_table)).to_dataframe()\n",
    "\n",
    "## Create copies to avoid calling bigquery multiple times when testing - comment out delete while testing\n",
    "game = game_bq.copy()\n",
    "player = player_bq.copy()\n",
    "\n",
    "#del game_bq\n",
    "#del player_bq\n",
    "\n",
    "## Create game variables needed for model\n",
    "game['home_spread'] = game['home_pts'].astype(int) - game['visitor_pts'].astype(int)\n",
    "game['season'] = ''\n",
    "for i in range(len(game)):\n",
    "    if ((game['game_date'][i].year != 2020 and game['game_date'][i].month < 7) or (game['game_date'][i].year == 2020 and game['game_date'][i].month < 11)):\n",
    "        game.loc[i,'season'] = game['game_date'][i].year\n",
    "    else:\n",
    "        game.loc[i,'season'] = game['game_date'][i].year + 1\n",
    "\n",
    "\n",
    "## Create game by team variables - stack home and away to team vs. opponent\n",
    "games_by_team_home = pd.DataFrame()\n",
    "games_by_team_home['season'] = game['season']\n",
    "games_by_team_home['game_key'] = game['game_key']\n",
    "games_by_team_home['game_key_team'] = game['game_key'] + 'h'\n",
    "games_by_team_home['game_key_opponent'] = game['game_key'] + 'a'\n",
    "games_by_team_home['game_date'] = pd.to_datetime(game['game_date'])\n",
    "games_by_team_home['team'] = game['home_team_name']\n",
    "games_by_team_home['opponent'] = game['visitor_team_name']\n",
    "games_by_team_home['is_home_team'] = 1\n",
    "games_by_team_home['spread'] = game['home_spread']\n",
    "games_by_team_home['pace'] = game['h_ff_pace']\n",
    "games_by_team_home['efg_pct'] = game['h_ff_efg_pct']\n",
    "games_by_team_home['tov_pct'] = game['h_ff_tov_pct']\n",
    "games_by_team_home['ft_rate'] = game['h_ff_ft_rate']\n",
    "games_by_team_home['off_rtg'] = game['h_ff_off_rtg']\n",
    "games_by_team_home['opponent_efg_pct'] = game['a_ff_efg_pct']\n",
    "games_by_team_home['opponent_tov_pct'] = game['a_ff_tov_pct']\n",
    "games_by_team_home['opponent_ft_rate'] = game['a_ff_ft_rate']\n",
    "games_by_team_home['opponent_off_rtg'] = game['a_ff_off_rtg']\n",
    "games_by_team_home['is_win'] = [1 if x > 0 else 0 for x in games_by_team_home['spread'].astype(int)]\n",
    "\n",
    "\n",
    "games_by_team_visitor = pd.DataFrame()\n",
    "games_by_team_visitor ['season'] = game['season']\n",
    "games_by_team_visitor['game_key'] = game['game_key']\n",
    "games_by_team_visitor ['game_key_team'] = game['game_key'] + 'a'\n",
    "games_by_team_visitor ['game_key_opponent'] = game['game_key'] + 'h'\n",
    "games_by_team_visitor ['game_date'] = pd.to_datetime(game['game_date'])\n",
    "games_by_team_visitor ['team'] = game['visitor_team_name']\n",
    "games_by_team_visitor ['opponent'] = game['home_team_name']\n",
    "games_by_team_visitor ['is_home_team'] = 0\n",
    "games_by_team_visitor ['spread'] = game['home_spread']*-1\n",
    "games_by_team_visitor ['pace'] = game['a_ff_pace']\n",
    "games_by_team_visitor ['efg_pct'] = game['a_ff_efg_pct']\n",
    "games_by_team_visitor ['tov_pct'] = game['a_ff_tov_pct']\n",
    "games_by_team_visitor ['ft_rate'] = game['a_ff_ft_rate']\n",
    "games_by_team_visitor ['off_rtg'] = game['a_ff_off_rtg']\n",
    "games_by_team_visitor['opponent_efg_pct'] = game['h_ff_efg_pct']\n",
    "games_by_team_visitor['opponent_tov_pct'] = game['h_ff_tov_pct']\n",
    "games_by_team_visitor['opponent_ft_rate'] = game['h_ff_ft_rate']\n",
    "games_by_team_visitor['opponent_off_rtg'] = game['h_ff_off_rtg']\n",
    "games_by_team_visitor['is_win'] = [1 if x > 0 else 0 for x in games_by_team_visitor['spread'].astype(int)]\n",
    "\n",
    "games_by_team = pd.concat([games_by_team_home,games_by_team_visitor])\n",
    "\n",
    "games_by_team.sort_values(by=['game_date'], ascending = True, inplace=True)\n",
    "\n",
    "games_by_team['previous_game_date'] = games_by_team.groupby(['team'])['game_date'].shift(1)\n",
    "\n",
    "games_by_team['incoming_rest_days'] = [(d - p).days for d,p in zip(games_by_team['game_date'],games_by_team['previous_game_date'])] \n",
    "\n",
    "# Replace NaN with -99 so can be converted to int. These rows will be dropped later.\n",
    "games_by_team['incoming_rest_days'].fillna(-99, inplace=True)\n",
    "\n",
    "games_by_team['incoming_rest_days'] = games_by_team['incoming_rest_days'].astype(int)\n",
    "\n",
    "games_by_team.set_index('game_key_team', inplace=True)\n",
    "\n",
    "# del games_by_team_visitor\n",
    "# del games_by_team_home\n",
    "\n",
    "## Create player variables needed for model\n",
    "# Make game key unique per home/away team\n",
    "player['game_key_team'] = player['game_key'] + player['h_or_a']\n",
    "\n",
    "#Only include players that actually played\n",
    "player = player.dropna(subset=['mp', 'plus_minus']).reset_index(drop=True)\n",
    "\n",
    "player['plus_minus'] = player['plus_minus'].astype(int)\n",
    "player['seconds_played'] = player['mp'].apply(convert_to_seconds)\n",
    "\n",
    "## Create dataframe for aggregated player stats per game\n",
    "game_player_stats = pd.DataFrame()\n",
    "game_player_stats['game_key_team'] = player['game_key_team'].unique()\n",
    "\n",
    "total_seconds = player.groupby(['game_key_team'])['seconds_played'].sum()\n",
    "starter_seconds = player[player['starter_flag']==True].groupby(['game_key_team'])['seconds_played'].sum()\n",
    "seconds = pd.merge(total_seconds, starter_seconds, left_index=True, right_index=True, how='inner')\n",
    "seconds['starter_minutes_played_proportion'] = seconds['seconds_played_y']/seconds['seconds_played_x']\n",
    "\n",
    "game_player_stats.set_index('game_key_team',inplace=True)\n",
    "game_player_stats = pd.merge(game_player_stats,seconds['starter_minutes_played_proportion'],left_index=True,right_index=True,how='inner')\n",
    "\n",
    "bench_pl_min = player[player['starter_flag']==False].groupby(['game_key_team'])['plus_minus'].sum()\n",
    "game_player_stats = pd.merge(game_player_stats,bench_pl_min, left_index=True, right_index=True, how='inner')\n",
    "game_player_stats = game_player_stats.rename(columns={'plus_minus':'bench_plus_minus'})\n",
    "\n",
    "## Merge aggregated stats in to games by team dataframe\n",
    "games_by_team = pd.merge(games_by_team,game_player_stats, left_index=True, right_index=True,how='inner')\n",
    "\n",
    "## Create dataframe to capture opponent aggregated stats\n",
    "game_player_stats_opponent = game_player_stats.copy()\n",
    "\n",
    "# del game_player_stats\n",
    "\n",
    "# Reset index so it can be modified to temporarily swith 'h' with 'a'\n",
    "game_player_stats_opponent.reset_index(drop=False, inplace=True)\n",
    "game_player_stats_opponent['game_key_team'] = game_player_stats_opponent['game_key_team'].apply(switch_key)\n",
    "\n",
    "#Rename columns to opponent columns\n",
    "game_player_stats_opponent = game_player_stats_opponent.rename(columns={'starter_minutes_played_proportion':'opponnent_starter_minutes_played_proportion','bench_plus_minus':'opponent_bench_plus_minus'})\n",
    "\n",
    "#Reset index and merge\n",
    "game_player_stats_opponent.set_index('game_key_team', inplace=True)\n",
    "games_by_team = pd.merge(games_by_team,game_player_stats_opponent,left_index=True,right_index=True,how='inner')\n",
    "\n",
    "# del game_player_stats_opponent\n",
    "\n",
    "games_by_team_with_wma = pd.DataFrame()\n",
    "#Create data frame with stats needed for model\n",
    "for team in games_by_team['team'].unique():\n",
    "    team_games = games_by_team.loc[games_by_team['team']==team].sort_values(by='game_date')\n",
    "    team_games = generate_streak_info(team_games,'is_win')\n",
    "    team_games['streak_counter_is_win'] = [x * -1 if y == 0 else x for x,y in zip(team_games['streak_counter_is_win'],team_games['is_win'])]\n",
    "    team_games['incoming_is_win_streak'] = team_games['streak_counter_is_win'].shift(fill_value=0)\n",
    "    for col in wma_columns:\n",
    "        team_games = create_linear_weighted_moving_average(team_games,col,W)\n",
    "        team_games[f'incoming_wma_{W}_{col}'] = team_games[f'wma_{W}_{col}'].shift()\n",
    "    games_by_team_with_wma = pd.concat([games_by_team_with_wma, team_games])\n",
    "\n",
    "games_by_team_with_wma = (games_by_team_with_wma.merge(games_by_team_with_wma.reset_index(drop=False)[[\n",
    "                'game_key_team','incoming_rest_days','streak_counter_is_win','incoming_is_win_streak']],\n",
    "                    left_on='game_key_opponent', right_on='game_key_team',\n",
    "                    how='inner', suffixes=(None, '_opponent'))) \n",
    "\n",
    "#Drop first W rows for each team with no incoming weighted average\n",
    "model_game_data = games_by_team_with_wma.dropna(subset=[f'incoming_wma_{W}_pace']).copy()\n",
    "\n",
    "# del games_by_team_with_wma\n",
    "# del games_by_team\n",
    "\n",
    "#Convert data types to prepare for load to bigquery\n",
    "model_game_data = model_game_data.astype({'season':int, 'is_win':int})\n",
    "\n",
    "#Create data frame to create firestore collections with data to use in model call\n",
    "most_recent_game = model_game_data.sort_values('game_date').drop_duplicates(['team'],keep='last')\n",
    "\n",
    "most_recent_game = most_recent_game[['season', 'game_date', 'team','streak_counter_is_win']\n",
    "                                                     + [f'wma_{W}_{x}' for x in wma_columns]]\n",
    "most_recent_game.reset_index(drop=True, inplace=True)\n",
    "most_recent_game.set_index('team', inplace=True)\n",
    "docs = most_recent_game.to_dict(orient='index')\n",
    "\n",
    "db = firestore.Client(project=my_project_id)\n",
    "for team in most_recent_game.index.unique():\n",
    "    doc_ref = db.collection('team_model_data').document(team.replace('/','\\\\')) #Teams that changed mid-season have a '/' which firestore interprets as new path\n",
    "    doc_ref.set(docs[team])\n",
    "\n",
    "# del most_recent_game\n",
    "\n",
    "#Create new client and load table to Big Query\n",
    "bqclient = bigquery.Client(project=my_project_id)\n",
    "#Publish model data\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect='True'\n",
    "job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "# job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "#     type_=bigquery.TimePartitioningType.DAY,\n",
    "#     field=\"game_date\")\n",
    "## Set schema for specific columns where more information is needed (e.g. not NULLABLE or specific date/time)\n",
    "job_config.schema = [\n",
    "    bigquery.SchemaField('game_key','STRING', 'REQUIRED'),\n",
    "    bigquery.SchemaField('team','STRING', 'REQUIRED'),\n",
    "    bigquery.SchemaField('opponent','STRING', 'REQUIRED'),\n",
    "    bigquery.SchemaField('game_date','DATE'),\n",
    "]\n",
    "job_model = bqclient.load_table_from_dataframe(model_game_data, model_table_name, job_config=job_config)\n",
    "\n",
    "model_result = job_model.result()\n",
    "model_message = (\n",
    "    f'Job ID: {model_result.job_id} '\n",
    "    f'was started {model_result.started} '\n",
    "    f'and ended {model_result.ended} '\n",
    "    f'loading {model_result.output_rows} row(s) '\n",
    "    f'to {model_result.destination}')\n",
    "\n",
    "print(model_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-facing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-charger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-product",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-relevance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(table, distinct_column):\n",
    "    ## Remove Duplicates - Always run at the end if you have had issues while loading ##\n",
    "    client = bigquery.Client(project=os.environ.get('GCP_PROJECT'))\n",
    "\n",
    "    ## Get row count and distinct game count\n",
    "    game_count = client.query('''\n",
    "    select count(1) as row_count,\n",
    "        count(distinct %s) as game_count \n",
    "        from `%s.%s`\n",
    "    ''' % (distinct_column,os.environ.get('GCP_PROJECT'),table)).to_dataframe()\n",
    "\n",
    "    if game_count['row_count'][0] == game_count['game_count'][0]:\n",
    "        return f'No duplicates in {table}!'\n",
    "    else:\n",
    "        deduplicate = client.query('''\n",
    "        CREATE OR REPLACE TABLE `%s.%s`\n",
    "        AS\n",
    "        SELECT * EXCEPT(row_num) FROM (\n",
    "        SELECT\n",
    "        *, ROW_NUMBER() OVER (PARTITION BY %s ORDER BY load_datetime desc) as row_num\n",
    "        FROM `%s.%s`\n",
    "        ) WHERE row_num = 1\n",
    "        ''' % (os.environ.get('GCP_PROJECT'),table,distinct_column,os.environ.get('GCP_PROJECT'),table))\n",
    "        return 'Duplicates removed from {table}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_remove = remove_duplicates('nba.raw_basketballreference_game','game_key')\n",
    "player_remove = remove_duplicates('nba.raw_basketballreference_playerbox', 'player_stat_key')\n",
    "\n",
    "print(game_remove)\n",
    "print(player_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GCP_PROJECT'] = 'nba-predictions-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "## Setup\n",
    "my_project_id = os.environ.get('GCP_PROJECT')\n",
    "client = bigquery.Client(project=my_project_id)\n",
    "raw_game_data_table = f'{my_project_id}.nba.raw_basketballreference_game'\n",
    "raw_player_data_table = f'{my_project_id}.nba.raw_basketballreference_playerbox'\n",
    "games_to_load_to_model_view = f'{my_project_id}.nba.games_to_load_to_model'\n",
    "model_table_name = f'{my_project_id}.nba.model_game'\n",
    "\n",
    "# Enter columns to created linearly weighted moving average calculations and number of periods to use\n",
    "wma_columns = ['pace',\n",
    "    'efg_pct', 'tov_pct', 'ft_rate', 'off_rtg',\n",
    "    'opponent_efg_pct', 'opponent_tov_pct', 'opponent_ft_rate',\n",
    "    'opponent_off_rtg', 'starter_minutes_played_proportion',\n",
    "    'bench_plus_minus', 'opponnent_starter_minutes_played_proportion',\n",
    "    'opponent_bench_plus_minus']\n",
    "W = 10\n",
    "\n",
    "## Load tables to dataframe\n",
    "game_bq = client.query('''\n",
    "SELECT game_date, visitor_team_name, visitor_pts, home_team_name, home_pts, games.game_key, \n",
    "    a_ff_pace, a_ff_efg_pct, a_ff_tov_pct, a_ff_orb_pct, a_ff_ft_rate, a_ff_off_rtg, \n",
    "    h_ff_pace, h_ff_efg_pct, h_ff_tov_pct,h_ff_orb_pct, h_ff_ft_rate, h_ff_off_rtg\n",
    "    ,NEEDS_TO_LOAD_TO_MODEL\n",
    "FROM `%s` as games\n",
    "INNER JOIN `%s` as load ON games.game_key = load.game_key \n",
    "''' % (raw_game_data_table,games_to_load_to_model_view)).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "if game_bq.empty:\n",
    "    print('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-trail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import firestore\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def predicted_pointspread(form_dict):\n",
    "    try:\n",
    "        teams = {'HomeTeam':'Atlanta Hawks', 'AwayTeam':'Milwaukee Bucks'}\n",
    "        df = pd.DataFrame(teams, index=[0])\n",
    "\n",
    "\n",
    "        db = firestore.Client()\n",
    "\n",
    "        home_team_data = db.collection('team_model_data').document(df['HomeTeam'][0]).get().to_dict()\n",
    "        away_team_data = db.collection('team_model_data').document(df['AwayTeam'][0]).get().to_dict()\n",
    "\n",
    "        query = 'SELECT predicted_spread FROM ML.PREDICT(MODEL `nba.automl_regression`, (SELECT 1 as is_home_team,'\n",
    "        for key in home_team_data.keys():\n",
    "            if key == 'streak_counter_is_win':\n",
    "                query = query + f'{home_team_data[key]} as incoming_is_win_streak,'\n",
    "            elif key not in ['season', 'game_date']:\n",
    "                query = query + f'{home_team_data[key]} as incoming_{key},'\n",
    "        for key in away_team_data.keys():\n",
    "            if key not in ['season', 'game_date', 'streak_counter_is_win']:\n",
    "                query = query + f'{away_team_data[key]} as incoming_opponent_{key},'\n",
    "\n",
    "        bq_query = query[:-1] + '))'\n",
    "\n",
    "        client = bigquery.Client()\n",
    "\n",
    "        game_bq = client.query('''\n",
    "        %s\n",
    "        ''' % (bq_query))\n",
    "\n",
    "        game = game_bq.to_dataframe()\n",
    "\n",
    "        pointspread = round(game['predicted_spread'][0],1)\n",
    "\n",
    "        if pointspread > 0:\n",
    "            winner = df['HomeTeam'][0]\n",
    "            loser = df['AwayTeam'][0]\n",
    "        else:\n",
    "            winner = df['AwayTeam'][0]\n",
    "            loser = df['HomeTeam'][0]\n",
    "        return f'I predict the {winner} will beat the {loser} by {abs(pointspread)} points!'\n",
    "    except Exception as e:\n",
    "        raise ValueError('Sorry, there was a problem processing the data entered... Please try again with different teams') from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointspread = np.random.randint(-1000,1000)\n",
    "pointspread = 1 if pointspread == 0 else pointspread\n",
    "if pointspread > 0:\n",
    "    winner = df['HomeTeam'][0]\n",
    "    loser = df['AwayTeam'][0]\n",
    "else:\n",
    "    winner = df['AwayTeam'][0]\n",
    "    loser = df['HomeTeam'][0]\n",
    "        return f'I predict the {winner} will beat the {loser} by {abs(pointspread)} points!'\n",
    "    except Exception as e:\n",
    "        raise ValueError('Sorry, there was a problem processing the data entered... Please go back and double check your entries, thanks!') from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flask import Flask, render_template, request#, url_for, redirect\n",
    "from google.cloud import storage\n",
    "from google.cloud import firestore\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CLOUD_STORAGE_BUCKET nba-predictions-dev.appspot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get(\"CLOUD_STORAGE_BUCKET\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "    client = storage.Client()\n",
    "    bucket_name = os.environ.get(\"CLOUD_STORAGE_BUCKET\") #'nba-predictions-dev.appspot.com'\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob = bucket.blob('static/monday.json').download_as_string()\n",
    "    data = json.loads(blob.decode(\"utf-8\").replace(\"'\",'\"'))\n",
    "    home_teams = list(data['home_team_name'].values())\n",
    "    away_teams = list(data['visitor_team_name'].values())\n",
    "    game_day = list(data['game_day'].values())\n",
    "    game_date = list(data['game_date'].values())\n",
    "    game_start_time = list(data['game_start_time'].values())\n",
    "    games = []\n",
    "    for i in range(len(home_teams)-1):\n",
    "        games.append(f'{away_teams[i]} vs. {home_teams[i]} at {game_start_time[i]} on {game_day[i]}, {game_date[i]}')\n",
    "    return render_template('UpcomingGames.html', games=games, home_teams = home_teams, away_teams=away_teams, game_day=game_day, game_date = game_date, game_start_time = game_start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-cross",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = {\"StartDate\":\"2015-02-01\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate = datetime.strptime(request['StartDate'], '%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "endDate_max = (datetime.now() + timedelta(days=-1)).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "endDate = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://us-central1-nba-predictions-dev.cloudfunctions.net/nba_basketball_reference_scraper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while endDate != endDate_max:\n",
    "year, month= divmod(startDate.month+1, 12)\n",
    "if month == 0: \n",
    "      month = 12\n",
    "      year = year -1\n",
    "endDate = date(startDate.year + year, month, 1) + timedelta(days=-1)\n",
    "if endDate >= endDate_max:\n",
    "    endDate = endDate_max\n",
    "endDateformat = endDate.strftime('%Y-%m-%d')\n",
    "startDateformat = startDate.strftime('%Y-%m-%d')\n",
    "data = {\"StartDate\":startDateformat,\"EndDate\":endDateformat}\n",
    "print(data)\n",
    "# response = requests.post(url, data)\n",
    "# print(response)\n",
    "year, month= divmod(startDate.month+1, 12)\n",
    "if month == 0: \n",
    "      month = 12\n",
    "      year = year -1\n",
    "startDate = date(startDate.year + year, month, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-helena",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_dict = {'HomeTeam':'Atlanta Hawks', 'AwayTeam':'Boston Celtics'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def predicted_pointspread(form_dict):\n",
    "    try:\n",
    "        df = pd.DataFrame(form_dict, index=[0])\n",
    "        pointspread = np.random.randint(-40,40)\n",
    "        pointspread = 1 if pointspread == 0 else pointspread\n",
    "        if pointspread > 0:\n",
    "            winner = df['HomeTeam'][0]\n",
    "            loser = df['AwayTeam'][0]\n",
    "        else:\n",
    "            winner = df['AwayTeam'][0]\n",
    "            loser = df['HomeTeam'][0]\n",
    "        return f'I predict the {winner} will beat the {loser} by {abs(pointspread)} points'\n",
    "    except:\n",
    "        return 'Sorry, there was a problem processing the data entered... Please go back and double check your entries, thanks!'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_pointspread(form_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(form_dict, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HomeTeam'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import pyarrow\n",
    "\n",
    "request = {'StartDate': '2019-10-01'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_game_date():\n",
    "    client = bigquery.Client(project=projcet)\n",
    "    \n",
    "    QUERY = (\n",
    "    \"SELECT date_add(max(game_date), INTERVAL 1 day) as max_game_date FROM `nba.raw_basketballreference_game`\"\n",
    "    )\n",
    "    query_job = client.query(QUERY)  # API request\n",
    "    rows = query_job.result()  # Waits for query to finish\n",
    "    \n",
    "    for result in rows:\n",
    "        load_date = result.max_game_date\n",
    "    \n",
    "    return load_date\n",
    "\n",
    "def get_game_players(soup, player_game_data, id_string, game_key, stat_type, h_or_a, team_abbrev, game_date):\n",
    "    rows = soup.find('table', id=id_string).find('tbody').find_all('tr')\n",
    "    cnt = 1\n",
    "\n",
    "    #print(str(rows))\n",
    "    for player in rows:\n",
    "        game_players = {}\n",
    "        game_players['game_key'] = game_key\n",
    "        game_players['game_date'] = game_date\n",
    "        game_players['h_or_a'] = h_or_a\n",
    "        game_players['team_abbrev'] = team_abbrev\n",
    "        game_players['stat_period'] = stat_type\n",
    "        game_players['player'] = player.find('th',{\"data-stat\": \"player\"}).text\n",
    "        #print(game_players['player'])\n",
    "        \n",
    "        player_node = player.find('th',{\"data-stat\": \"player\"})\n",
    "        \n",
    "        # Ignore Header Line\n",
    "        if game_players['player'] != 'Reserves' and player_node.has_attr('data-append-csv'):\n",
    "        \n",
    "            a = player.find('th',{\"data-stat\": \"player\"}).find('a',href=True)\n",
    "            if a is not None:\n",
    "                game_players['player_link'] = a['href']\n",
    "            else:\n",
    "                game_players['player_link'] = None\n",
    "            \n",
    "            game_players['player_key'] = player_node['data-append-csv']\n",
    "            game_players['reason'] = get_text(player.find('td',{\"data-stat\": \"reason\"}))\n",
    "            game_players['mp'] = get_text(player.find('td',{\"data-stat\": \"mp\"}))\n",
    "            game_players['fg'] = get_text(player.find('td',{\"data-stat\": \"fg\"}))\n",
    "            game_players['fga'] = get_text(player.find('td',{\"data-stat\": \"fga\"}))\n",
    "            game_players['fg_pct'] = get_text(player.find('td',{\"data-stat\": \"fg_pct\"}))\n",
    "            game_players['fg3'] = get_text(player.find('td',{\"data-stat\": \"fg3\"}))\n",
    "            game_players['fg3a'] = get_text(player.find('td',{\"data-stat\": \"fg3a\"}))\n",
    "            game_players['fg3_pct'] = get_text(player.find('td',{\"data-stat\": \"fg3_pct\"}))\n",
    "            game_players['ft'] = get_text(player.find('td',{\"data-stat\": \"ft\"}))\n",
    "            game_players['fta'] = get_text(player.find('td',{\"data-stat\": \"fta\"}))\n",
    "            game_players['ft_pct'] = get_text(player.find('td',{\"data-stat\": \"ft_pct\"}))\n",
    "            game_players['orb'] = get_text(player.find('td',{\"data-stat\": \"orb\"}))\n",
    "            game_players['drb'] = get_text(player.find('td',{\"data-stat\": \"drb\"}))\n",
    "            game_players['trb'] = get_text(player.find('td',{\"data-stat\": \"trb\"}))\n",
    "            game_players['ast'] = get_text(player.find('td',{\"data-stat\": \"ast\"}))\n",
    "            game_players['stl'] = get_text(player.find('td',{\"data-stat\": \"stl\"}))\n",
    "            game_players['blk'] = get_text(player.find('td',{\"data-stat\": \"blk\"}))\n",
    "            game_players['tov'] = get_text(player.find('td',{\"data-stat\": \"tov\"}))\n",
    "            game_players['pf'] = get_text(player.find('td',{\"data-stat\": \"pf\"}))\n",
    "            game_players['pts'] = get_text(player.find('td',{\"data-stat\": \"pts\"}))\n",
    "            game_players['plus_minus'] = get_text(player.find('td',{\"data-stat\": \"plus_minus\"}))\n",
    "            game_players['player_stat_key'] = game_players['game_key'] + '|' + game_players['player_key'] + '|' + game_players['stat_period'] \n",
    "            if cnt <= 5:\n",
    "                game_players['starter_flag'] = True \n",
    "            else:\n",
    "                game_players['starter_flag'] = False\n",
    "            game_players['load_datetime'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  \n",
    "            #print(game_players)\n",
    "            player_game_data.append(game_players)\n",
    "            cnt += 1\n",
    "\n",
    "    return player_game_data\n",
    "   \n",
    "def get_text(stat):\n",
    "    if stat is not None:\n",
    "        if stat.text != \"\":\n",
    "            txt = stat.text\n",
    "        else:\n",
    "            txt = None\n",
    "    else:\n",
    "        txt = None\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    ##########################################################################\n",
    "    # Input Data Check\n",
    "    ##########################################################################\n",
    "    \n",
    "    try:\n",
    "        request_json = request\n",
    "        if request_json and 'StartDate' in request_json:  \n",
    "            startDate = datetime.strptime(request_json['StartDate'], '%Y-%m-%d').date()            \n",
    "        else:\n",
    "            startDate = get_max_game_date()\n",
    "        if request_json and 'EndDate' in request_json:  \n",
    "            endDate = datetime.strptime(request_json['EndDate'], '%Y-%m-%d').date() \n",
    "        else:\n",
    "            endDate = (datetime.now() + timedelta(days=-1)).date()\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Start & End dates must be in YYYY-MM-DD format\") from e\n",
    "\n",
    "    # Distinct list of Months between start and end date\n",
    "    delta = endDate - startDate       # as timedelta\n",
    "\n",
    "    if delta.days < 0:\n",
    "        raise ValueError(\"Start Date can't be before End Date\") \n",
    "    \n",
    "    ##########################################################################\n",
    "    # Get Distinct Months for schedule to scrape\n",
    "    ##########################################################################\n",
    "    \n",
    "    yearmonths = []\n",
    "    for i in range(delta.days + 1):\n",
    "        r = {}\n",
    "        day = startDate + timedelta(days=i)\n",
    "        r['monthname'] = day.strftime('%B').lower()\n",
    "        if day.month > 9:\n",
    "            r['year'] = day.year + 1\n",
    "        else:\n",
    "            r['year'] = day.year\n",
    "        if r not in yearmonths: \n",
    "            yearmonths.append(r)\n",
    "    #print(yearmonths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearmonths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-stanley",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "##########################################################################\n",
    "# Scrape Schedule\n",
    "##########################################################################\n",
    "player_game_rows_loaded = 0\n",
    "game_rows_loaded = 0\n",
    "\n",
    "\n",
    "schedule = []\n",
    "v = yearmonths[12]\n",
    "year = str(v['year'])\n",
    "month = v['monthname']\n",
    "if month == 'october' and (year == '2020' or year == '2021'):\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}-{v[\"year\"] - 1}.html'\n",
    "else:\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{year}_games-{month}.html'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(url)\n",
    "\n",
    "if html.ok:\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')  \n",
    "else:\n",
    "    print(f'No data for {month} {year} because enountered error code {html.status_code}')\n",
    "    #continue\n",
    "\n",
    "rows = soup.find('table', id=\"schedule\").find('tbody').find_all('tr')\n",
    "#print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    game_date_node = row.find('th',{\"data-stat\": \"date_game\"})\n",
    "    if game_date_node is not None:\n",
    "\n",
    "        game_date = datetime.strptime(game_date_node.text, '%a, %b %d, %Y').date()\n",
    "        if game_date >= startDate and game_date <= endDate:\n",
    "            #cells = row.find_all(['td', 'th'])\n",
    "            r = {}\n",
    "            #r.setdefault(game_start_time, []).append(value)\n",
    "\n",
    "            v1 = row.find('th',{\"data-stat\": \"date_game\"})\n",
    "            #r[k1] = v1.text\n",
    "            r['game_date'] = datetime.strptime(v1.text, '%a, %b %d, %Y').strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            v2 = row.find('td',{\"data-stat\": \"game_start_time\"})\n",
    "            r['game_start_time'] = v2.text if v2 else None\n",
    "\n",
    "            v3 = row.find('td',{\"data-stat\": \"visitor_team_name\"})\n",
    "            r['visitor_team_name'] = v3.text\n",
    "            r['away_abbr'] = v3['csk'].split('.')[0]\n",
    "\n",
    "            v4 = row.find('td',{\"data-stat\": \"visitor_pts\"})\n",
    "            r['visitor_pts'] = v4.text if v4 else None\n",
    "\n",
    "            v5 = row.find('td',{\"data-stat\": \"home_team_name\"})\n",
    "            r['home_team_name'] = v5.text\n",
    "            r['home_abbr'] = v5['csk'].split('.')[0]\n",
    "\n",
    "            v6 = row.find('td',{\"data-stat\": \"home_pts\"})\n",
    "            r['home_pts'] = v6.text if v6 else None\n",
    "\n",
    "            v7 = row.find('td',{\"data-stat\": \"box_score_text\"}).find('a',href=True)\n",
    "            r['box_score_url'] = v7['href'] if v7 else None\n",
    "\n",
    "            v8 = row.find('td',{\"data-stat\": \"attendance\"})\n",
    "            r['attendance'] = v8.text if v8 else None\n",
    "\n",
    "            v9 = row.find('td',{\"data-stat\": \"overtimes\"})\n",
    "            r['overtimes'] = v9.text if v9 else None\n",
    "\n",
    "            if r['game_start_time']:\n",
    "                v12 = r['away_abbr'] + r['game_date'].replace('-','') + r['home_abbr'] + r['game_start_time'].replace(':','')\n",
    "            else:\n",
    "                v12 = r['away_abbr'] + r['game_date'].replace('-','') + r['home_abbr']\n",
    "            r['game_key'] = v12 if v12 else None\n",
    "\n",
    "            schedule.append(r)\n",
    "print(schedule)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "            ##########################################################################\n",
    "            # Scrape Games in Schedule\n",
    "            ##########################################################################\n",
    "            games_data = []\n",
    "            player_game_data = []\n",
    "\n",
    "            for game in schedule:\n",
    "                if 'box_score_url' in game and game['box_score_url'] != \"\" and game['box_score_url'] is not None:\n",
    "\n",
    "\n",
    "                    url = \"https://www.basketball-reference.com\" + game['box_score_url']\n",
    "\n",
    "                    #print(url)\n",
    "                    r = requests.get(url)\n",
    "                    #print('here2')\n",
    "                    soup = BeautifulSoup(str(r.content).replace(\"<!--\",\"\").replace('-->',''), 'html.parser')\n",
    "\n",
    "                    ##############################################\n",
    "                    # Line Score\n",
    "                    rows = soup.find('table', id=\"line_score\").find_all('tr')\n",
    "\n",
    "                    # Away Line Score\n",
    "                    r_num = 1\n",
    "                    for away in rows[2].find_all('td'):\n",
    "                        test_strong = away.find('strong') # Strong represents the total score ... ignore\n",
    "                        if test_strong is None and r_num < 7:\n",
    "                            k='a_g' + str(r_num) + '_score'\n",
    "                            game[k] = away.text if away.text != \"\" else None\n",
    "                        r_num+=1\n",
    "\n",
    "                    # Home Line Score\n",
    "                    r_num = 1\n",
    "                    for home in rows[3].find_all('td'):\n",
    "                        test_strong = home.find('strong') # Strong represents the total score ... ignore\n",
    "                        if test_strong is None and r_num < 7:\n",
    "                            k='h_g' + str(r_num) + '_score'\n",
    "                            game[k] = home.text if home.text != \"\" else None\n",
    "                        r_num+=1    \n",
    "\n",
    "                    ##############################################\n",
    "                    # Four Facts\n",
    "                    rows = soup.find('table', id=\"four_factors\").find_all('tr')\n",
    "\n",
    "                    # Away Four Factors\n",
    "                    game['a_ff_pace'] = rows[2].find('td',{\"data-stat\": \"pace\"}).text\n",
    "                    game['a_ff_efg_pct'] = rows[2].find('td',{\"data-stat\": \"efg_pct\"}).text\n",
    "                    game['a_ff_tov_pct'] = rows[2].find('td',{\"data-stat\": \"tov_pct\"}).text\n",
    "                    game['a_ff_orb_pct'] = rows[2].find('td',{\"data-stat\": \"orb_pct\"}).text\n",
    "                    game['a_ff_ft_rate'] = rows[2].find('td',{\"data-stat\": \"ft_rate\"}).text\n",
    "                    game['a_ff_off_rtg'] = rows[2].find('td',{\"data-stat\": \"off_rtg\"}).text\n",
    "\n",
    "                    # Home Four Factors\n",
    "                    game['h_ff_pace'] = rows[3].find('td',{\"data-stat\": \"pace\"}).text\n",
    "                    game['h_ff_efg_pct'] = rows[3].find('td',{\"data-stat\": \"efg_pct\"}).text\n",
    "                    game['h_ff_tov_pct'] = rows[3].find('td',{\"data-stat\": \"tov_pct\"}).text\n",
    "                    game['h_ff_orb_pct'] = rows[3].find('td',{\"data-stat\": \"orb_pct\"}).text\n",
    "                    game['h_ff_ft_rate'] = rows[3].find('td',{\"data-stat\": \"ft_rate\"}).text\n",
    "                    game['h_ff_off_rtg'] = rows[3].find('td',{\"data-stat\": \"off_rtg\"}).text\n",
    "                    game['load_datetime'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")        \n",
    "\n",
    "                    #now = datetime.now() # current date and time\n",
    "                    #now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "\n",
    "                    #player_game_data = []\n",
    "                    game_date = game['game_date']\n",
    "\n",
    "                    ##############################################\n",
    "                    # Game Box - Home\n",
    "                    #box-WAS-q1-basic\n",
    "                    stat_type = \"game\"\n",
    "                    h_or_a = \"h\"\n",
    "                    team_abbrev = game['home_abbr']\n",
    "                    id_string = \"box-\" + game['home_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "                    player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "                    ##############################################\n",
    "                    # Game Box - Away\n",
    "                    #box-WAS-q1-basic\n",
    "                    stat_type = \"game\"\n",
    "                    h_or_a = \"a\"\n",
    "                    team_abbrev = game['away_abbr']\n",
    "                    id_string = \"box-\" + game['away_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "                    player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q1 Box - Home\n",
    "#                     stat_type = \"q1\"\n",
    "#                     h_or_a = \"h\"\n",
    "#                     team_abbrev = game['home_abbr']\n",
    "#                     id_string = \"box-\" + game['home_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q1 Box - Away\n",
    "#                     stat_type = \"q1\"\n",
    "#                     h_or_a = \"a\"\n",
    "#                     team_abbrev = game['away_abbr']\n",
    "#                     id_string = \"box-\" + game['away_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q2 Box - Home\n",
    "#                     stat_type = \"q2\"\n",
    "#                     h_or_a = \"h\"\n",
    "#                     team_abbrev = game['home_abbr']\n",
    "#                     id_string = \"box-\" + game['home_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q2 Box - Away\n",
    "#                     stat_type = \"q2\"\n",
    "#                     h_or_a = \"a\"\n",
    "#                     team_abbrev = game['away_abbr']\n",
    "#                     id_string = \"box-\" + game['away_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q3 Box - Home\n",
    "#                     stat_type = \"q3\"\n",
    "#                     h_or_a = \"h\"\n",
    "#                     team_abbrev = game['home_abbr']\n",
    "#                     id_string = \"box-\" + game['home_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q3 Box - Away\n",
    "#                     stat_type = \"q3\"\n",
    "#                     h_or_a = \"a\"\n",
    "#                     team_abbrev = game['away_abbr']\n",
    "#                     id_string = \"box-\" + game['away_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q4 Box - Home\n",
    "#                     stat_type = \"q4\"\n",
    "#                     h_or_a = \"h\"\n",
    "#                     team_abbrev = game['home_abbr']\n",
    "#                     id_string = \"box-\" + game['home_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "#                     ##############################################\n",
    "#                     # Q4 Box - Away\n",
    "#                     stat_type = \"q4\"\n",
    "#                     h_or_a = \"a\"\n",
    "#                     team_abbrev = game['away_abbr']\n",
    "#                     id_string = \"box-\" + game['away_abbr'] + \"-\" + stat_type + \"-basic\"\n",
    "#                     player_game_data = get_game_players(soup, player_game_data, id_string, game['game_key'], stat_type, h_or_a, team_abbrev, game_date)\n",
    "\n",
    "                    games_data.append(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_games_data = pd.DataFrame(games_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_games_data['game_start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "            ##########################################################################\n",
    "            # Check for empty game data\n",
    "            ##########################################################################\n",
    "            # Continue to next month if there were no games in the month starting at the start date\n",
    "            if not games_data:\n",
    "                continue                    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'nba-predictions-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "            ##########################################################################\n",
    "            # Save to BigQuery\n",
    "            ##########################################################################\n",
    "\n",
    "            # print(player_game_data)\n",
    "            # print(games_data)\n",
    "\n",
    "            # Config\n",
    "            client = bigquery.Client(project=project)\n",
    "            print(f'Loading data for {month} {year}')\n",
    "            \n",
    "            #player game data\n",
    "            pandas_player_game_data = pd.DataFrame(player_game_data)\n",
    "            pandas_player_game_data['game_date'] = pandas_player_game_data['game_date'].astype('datetime64[ns]')\n",
    "            pandas_player_game_data['load_datetime'] = pandas_player_game_data['load_datetime'].astype('datetime64[ns]')\n",
    "            job_config = bigquery.LoadJobConfig()\n",
    "            job_config.autodetect='True'\n",
    "            job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "            job_config.write_disposition = 'WRITE_APPEND'\n",
    "             ## Set schema for specific columns where more information is needed (e.g. not NULLABLE or specific date/time)\n",
    "            job_config.schema = [\n",
    "                bigquery.SchemaField('player_stat_key','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('game_date','DATE'),\n",
    "                bigquery.SchemaField('load_datetime','TIMESTAMP'),\n",
    "                bigquery.SchemaField('starter_flag','BOOL')\n",
    "            ]\n",
    "            job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"game_date\")\n",
    "            job_player = client.load_table_from_dataframe(pandas_player_game_data, 'nba.raw_basketballreference_playerbox' \\\n",
    "                                                          , job_config=job_config, project=project)\n",
    "            player_result = job_player.result()\n",
    "            player_message = (\n",
    "                f'Job ID: {player_result.job_id} '\n",
    "                f'was started {player_result.started} '\n",
    "                f'and ended {player_result.ended} '\n",
    "                f'loading {player_result.output_rows} row(s) '\n",
    "                f'to {player_result.destination}')\n",
    "            print(player_message)\n",
    "            player_game_rows_loaded = player_game_rows_loaded + player_result.output_rows\n",
    "\n",
    "            #game data\n",
    "            pandas_games_data = pd.DataFrame(games_data)\n",
    "            pandas_games_data['game_date'] = pandas_games_data['game_date'].astype('datetime64[ns]')\n",
    "            pandas_games_data['load_datetime'] = pandas_games_data['load_datetime'].astype('datetime64[ns]')\n",
    "            job_config = bigquery.LoadJobConfig()\n",
    "            job_config.autodetect='True'\n",
    "            job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "            job_config.write_disposition = 'WRITE_APPEND'\n",
    "            ## Set schema for specific columns where more information is needed (e.g. not NULLABLE or specific date/time)\n",
    "            job_config.schema = [\n",
    "                bigquery.SchemaField('game_key','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('game_date','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('home_team_name','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('home_abbr','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('visitor_team_name','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('away_abbr','STRING', 'REQUIRED'),\n",
    "                bigquery.SchemaField('game_date','DATE'),\n",
    "                bigquery.SchemaField('load_datetime','TIMESTAMP'),\n",
    "            ]\n",
    "            job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "                type_=bigquery.TimePartitioningType.DAY,\n",
    "                field=\"game_date\")\n",
    "            job_game = client.load_table_from_dataframe(pandas_games_data, 'nba.raw_basketballreference_game', \\\n",
    "                                                        job_config=job_config, project=project)\n",
    "            game_result = job_game.result()\n",
    "            game_message = (\n",
    "                f'Job ID: {game_result.job_id} '\n",
    "                f'was started {game_result.started} '\n",
    "                f'and ended {game_result.ended} '\n",
    "                f'loading {game_result.output_rows} row(s) '\n",
    "                f'to {game_result.destination}')\n",
    "            print(game_message)\n",
    "            game_rows_loaded = game_rows_loaded + game_result.output_rows\n",
    "\n",
    "            print(f'Successfully loaded {player_game_rows_loaded} row(s) to raw_basketballreference_playerbox and {game_rows_loaded} to raw_basketballreference_game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-winning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def get_games(startDate,endDate):\n",
    "    ##########################################################################\n",
    "    # Get Distinct Months for schedule to scrape\n",
    "    ##########################################################################\n",
    "\n",
    "    delta = endDate - startDate\n",
    "    \n",
    "    yearmonths = []\n",
    "    for i in range(delta.days + 1):\n",
    "        r = {}\n",
    "        day = startDate + timedelta(days=i)\n",
    "        r['monthname'] = day.strftime('%B').lower()\n",
    "        if day.month > 9:\n",
    "            r['year'] = day.year + 1\n",
    "        else:\n",
    "            r['year'] = day.year\n",
    "        if r not in yearmonths: \n",
    "            yearmonths.append(r)\n",
    "\n",
    "    schedule = []\n",
    "    for v in yearmonths:\n",
    "        year = str(v['year'])\n",
    "        month = v['monthname']\n",
    "        url = 'https://www.basketball-reference.com/leagues/NBA_' + year + '_games-' + month + '.html'\n",
    "        #print(url)\n",
    "\n",
    "        html = requests.get(url)\n",
    "\n",
    "        if html.ok:\n",
    "            soup = BeautifulSoup(html.content, 'html.parser')  \n",
    "        else:\n",
    "            print(f'No data for {month} {year} because enountered error code {html.status_code}')\n",
    "            continue\n",
    "\n",
    "        rows = soup.find('table', id=\"schedule\").find('tbody').find_all('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            game_date_node = row.find('th',{\"data-stat\": \"date_game\"})\n",
    "            if game_date_node is not None:\n",
    "\n",
    "                game_date = datetime.strptime(game_date_node.text, '%a, %b %d, %Y').date()\n",
    "                if game_date >= startDate and game_date <= endDate:\n",
    "                    #cells = row.find_all(['td', 'th'])\n",
    "                    r = {}\n",
    "                    #r.setdefault(game_start_time, []).append(value)\n",
    "\n",
    "                    v1 = row.find('th',{\"data-stat\": \"date_game\"})\n",
    "                    #r[k1] = v1.text\n",
    "                    r['game_date'] = datetime.strptime(v1.text, '%a, %b %d, %Y').strftime(\"%Y-%m-%d\")\n",
    "                    r['game_day'] = datetime.strptime(v1.text, '%a, %b %d, %Y').strftime(\"%A\")\n",
    "\n",
    "                    v2 = row.find('td',{\"data-stat\": \"game_start_time\"})\n",
    "                    r['game_start_time'] = v2.text if v2 else None\n",
    "\n",
    "                    v3 = row.find('td',{\"data-stat\": \"visitor_team_name\"})\n",
    "                    r['visitor_team_name'] = v3.text\n",
    "                    r['away_abbr'] = v3['csk'].split('.')[0]\n",
    "\n",
    "                    v4 = row.find('td',{\"data-stat\": \"home_team_name\"})\n",
    "                    r['home_team_name'] = v4.text\n",
    "                    r['home_abbr'] = v4['csk'].split('.')[0]\n",
    "\n",
    "                    if r['game_start_time']:\n",
    "                        v12 = r['away_abbr'] + r['game_date'].replace('-','') + r['home_abbr'] + r['game_start_time'].replace(':','')\n",
    "                    else:\n",
    "                        v12 = r['away_abbr'] + r['game_date'].replace('-','') + r['home_abbr']\n",
    "                    r['game_key'] = v12 if v12 else None\n",
    "\n",
    "                    schedule.append(r)\n",
    "                \n",
    "    return schedule\n",
    "\n",
    "def write_to_bucket(request):\n",
    "    \n",
    "    try:\n",
    "        if type(request) == 'dict':\n",
    "            request_json = request\n",
    "        else:\n",
    "            request_json = request.get_json()      \n",
    "        if request_json and 'ScheduleDays' in request_json:\n",
    "            schedule_days = request_json['ScheduleDays']\n",
    "        else:\n",
    "            schedule_days = 14\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Invalid input. Please provide ScheduleDays as an integer\") from e\n",
    "    \n",
    "    startDate = (datetime.now()).date()\n",
    "    endDate = (startDate + timedelta(days=schedule_days))\n",
    "    schedule = get_games(startDate,endDate) \n",
    "    \n",
    "    game_date = pd.DataFrame(schedule)\n",
    "    client = storage.Client()\n",
    "    bucket_name = os.environ.get(\"CLOUD_STORAGE_BUCKET\")\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    bucket.blob('static/upcoming.json').upload_from_string(game_date.to_json(), 'text/json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-elephant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from io import StringIO # if going with no saving csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-highway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.blob('static/monday.csv').upload_from_string(game_date[game_date['game_day']=='Monday'].to_csv(), 'text/csv')\n",
    "bucket.blob('static/tuesday.csv').upload_from_string(game_date[game_date['game_day']=='Tuesday'].to_csv(), 'text/csv')\n",
    "bucket.blob('static/wednesday.csv').upload_from_string(game_date[game_date['game_day']=='Wednesday'].to_csv(), 'text/csv')\n",
    "bucket.blob('static/thursday.csv').upload_from_string(game_date[game_date['game_day']=='Thursday'].to_csv(), 'text/csv')\n",
    "bucket.blob('static/friday.csv').upload_from_string(game_date[game_date['game_day']=='Friday'].to_csv(), 'text/csv')\n",
    "bucket.blob('static/saturday.csv').upload_from_string(game_date[game_date['game_day']=='Saturday'].to_csv(), 'text/csv')\n",
    "bucket.blob('static/sunday.csv').upload_from_string(game_date[game_date['game_day']=='Sunday'].to_csv(), 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_date[game_date['game_day']=='Monday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.blob('static/monday.json').upload_from_string(game_date[game_date['game_day']=='Monday'].to_json(), 'text/json')\n",
    "bucket.blob('static/tuesday.json').upload_from_string(game_date[game_date['game_day']=='Tuesday'].to_json(), 'text/json')\n",
    "bucket.blob('static/wednesday.json').upload_from_string(game_date[game_date['game_day']=='Wednesday'].to_json(), 'text/json')\n",
    "bucket.blob('static/thursday.json').upload_from_string(game_date[game_date['game_day']=='Thursday'].to_json(), 'text/json')\n",
    "bucket.blob('static/friday.json').upload_from_string(game_date[game_date['game_day']=='Friday'].to_json(), 'text/json')\n",
    "bucket.blob('static/saturday.json').upload_from_string(game_date[game_date['game_day']=='Saturday'].to_json(), 'text/json')\n",
    "bucket.blob('static/sunday.json').upload_from_string(game_date[game_date['game_day']=='Sunday'].to_json(), 'text/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.bucket('nba-predictions-dev.appspot.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cpt = StringIO(bucket.blob('static/monday.json').download_as_string())\n",
    "df = pd.read_csv(d_cpt)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data = json.loads(blob.decode(\"utf-8\").replace(\"'\",'\"'))\n",
    "    home_teams = list(data['home_team_name'].values())\n",
    "    away_teams = list(data['visitor_team_name'].values())\n",
    "    game_day = list(data['game_day'].values())\n",
    "    game_date = list(data['game_date'].values())\n",
    "    game_start_time = list(data['game_start_time'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = []\n",
    "for i in range(len(home_teams)-1):\n",
    "    games.append(f'{away_teams[i]} vs. {home_teams[i]} at {game_start_time[i]} on {game_day[i]}, {game_date[i]}')\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_teams[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(home_teams)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob('static/monday.json').download_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = json.loads(blob.decode(\"utf-8\").replace(\"'\",'\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict['home_team_name'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict['visitor_team_name'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.get_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.download_as_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob2 = bucket.blob('monday.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "polish-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "divided-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-variance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
