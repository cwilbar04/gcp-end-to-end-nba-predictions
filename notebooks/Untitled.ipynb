{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "secret-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from firebase_admin import firestore\n",
    "import os\n",
    "\n",
    "## Insert initial setup in entry point function: create_model_data\n",
    "\n",
    "def convert_to_seconds(x):\n",
    "    sp = int(x.split(':')[0]) * 60 + int(x.split(':')[1])\n",
    "    return sp\n",
    "\n",
    "def switch_key(key):\n",
    "    new_key = key[:-1] + ('h' if key[-1] == 'a' else 'a')\n",
    "    return new_key\n",
    "\n",
    "def generate_streak_info(data,column):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate streak data\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate streak info\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_streak_counter:\n",
    "        The original dataframe with a new column\n",
    "        `streak_counter_[column]` containing integers with \n",
    "        counts for each streak.\n",
    "    \"\"\"\n",
    "    \n",
    "    data['start_of_streak'] = data[column].ne(data[column].shift())\n",
    "    data['streak_id'] = data.start_of_streak.cumsum()\n",
    "    data[f'streak_counter_{column}'] = data.groupby('streak_id').cumcount() + 1\n",
    "    data_with_streak_counter = data.drop(columns = ['start_of_streak','streak_id'] )\n",
    "    return data_with_streak_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "satisfied-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_weighted_moving_average(data,column,W):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate weighted moving average.\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate weighted moving average info.\n",
    "      Column must be ready to be converted to float data type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_moving_average:\n",
    "        The original dataframe with a new column\n",
    "        `wma_[W]_[column]` containing float values with weighted moving average\n",
    "        values for the provided value with a weight of W.\n",
    "    \"\"\"  \n",
    "    data_with_moving_average = data.copy()\n",
    "    data_with_moving_average[column] = data_with_moving_average[column].astype(float)\n",
    "    weights = np.arange(1,W+1)\n",
    "    data_with_moving_average[f'wma_{W}_{column}'] = data_with_moving_average[column].rolling(W).apply(lambda col: np.dot(col, weights)/weights.sum(), raw=True)\n",
    "    return data_with_moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "floral-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Setup\n",
    "    my_project_id = os.environ.get('GCP_PROJECT')\n",
    "    client = bigquery.Client(project=my_project_id)\n",
    "    raw_game_data_table = 'nba.raw_basketballreference_game'\n",
    "    raw_player_data_table = 'nba.raw_basketballreference_playerbox'\n",
    "    model_table_name = 'nba.model_game'\n",
    "\n",
    "    # Enter columns to created linearly weighted moving average calculations and number of periods to use\n",
    "    wma_columns = ['pace',\n",
    "        'efg_pct', 'tov_pct', 'ft_rate', 'off_rtg',\n",
    "        'opponent_efg_pct', 'opponent_tov_pct', 'opponent_ft_rate',\n",
    "        'opponent_off_rtg', 'starter_minutes_played_proportion',\n",
    "        'bench_plus_minus', 'opponnent_starter_minutes_played_proportion',\n",
    "        'opponent_bench_plus_minus']\n",
    "    W = 10\n",
    "    \n",
    "    ## Load tables to dataframe\n",
    "    game = client.query('''\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `%s`\n",
    "    ''' % (raw_game_data_table)).to_dataframe()\n",
    "\n",
    "    player = client.query('''\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `%s`\n",
    "    ''' % (raw_player_data_table)).to_dataframe()\n",
    "\n",
    "    ## Create game variables needed for model\n",
    "    game['home_spread'] = game['home_pts'].astype(int) - game['visitor_pts'].astype(int)\n",
    "    game['season'] = ''\n",
    "    for i in range(len(game)):\n",
    "        if ((game['game_date'][i].year != 2020 and game['game_date'][i].month < 7) or (game['game_date'][i].year == 2020 and game['game_date'][i].month < 11)):\n",
    "            game.loc[i,'season'] = game['game_date'][i].year\n",
    "        else:\n",
    "            game.loc[i,'season'] = game['game_date'][i].year + 1\n",
    "\n",
    "\n",
    "    ## Create game by team variables - stack home and away to team vs. opponent\n",
    "    games_by_team_home = pd.DataFrame()\n",
    "    games_by_team_home['season'] = game['season']\n",
    "    games_by_team_home['game_key'] = game['game_key'] + 'h'\n",
    "    games_by_team_home['game_date'] = pd.to_datetime(game['game_date'])\n",
    "    games_by_team_home['team'] = game['home_team_name']\n",
    "    games_by_team_home['opponent'] = game['visitor_team_name']\n",
    "    games_by_team_home['is_home_team'] = 1\n",
    "    games_by_team_home['spread'] = game['home_spread']\n",
    "    games_by_team_home['pace'] = game['h_ff_pace']\n",
    "    games_by_team_home['efg_pct'] = game['h_ff_efg_pct']\n",
    "    games_by_team_home['tov_pct'] = game['h_ff_tov_pct']\n",
    "    games_by_team_home['ft_rate'] = game['h_ff_ft_rate']\n",
    "    games_by_team_home['off_rtg'] = game['h_ff_off_rtg']\n",
    "    games_by_team_home['opponent_efg_pct'] = game['a_ff_efg_pct']\n",
    "    games_by_team_home['opponent_tov_pct'] = game['a_ff_tov_pct']\n",
    "    games_by_team_home['opponent_ft_rate'] = game['a_ff_ft_rate']\n",
    "    games_by_team_home['opponent_off_rtg'] = game['a_ff_off_rtg']\n",
    "\n",
    "\n",
    "    games_by_team_home['is_win'] = ''\n",
    "    for i in range(len(game)):\n",
    "        games_by_team_home.loc[i,'is_win'] = 1 if game['home_spread'][i].astype(int) > 0 else 0\n",
    "\n",
    "\n",
    "    games_by_team_visitor = pd.DataFrame()\n",
    "    games_by_team_visitor ['season'] = game['season']\n",
    "    games_by_team_visitor ['game_key'] = game['game_key'] + 'a'\n",
    "    games_by_team_visitor ['game_date'] = pd.to_datetime(game['game_date'])\n",
    "    games_by_team_visitor ['team'] = game['visitor_team_name']\n",
    "    games_by_team_visitor ['opponent'] = game['home_team_name']\n",
    "    games_by_team_visitor ['is_home_team'] = 0\n",
    "    games_by_team_visitor ['spread'] = game['home_spread']*-1\n",
    "    games_by_team_visitor ['pace'] = game['a_ff_pace']\n",
    "    games_by_team_visitor ['efg_pct'] = game['a_ff_efg_pct']\n",
    "    games_by_team_visitor ['tov_pct'] = game['a_ff_tov_pct']\n",
    "    games_by_team_visitor ['ft_rate'] = game['a_ff_ft_rate']\n",
    "    games_by_team_visitor ['off_rtg'] = game['a_ff_off_rtg']\n",
    "    games_by_team_visitor['opponent_efg_pct'] = game['h_ff_efg_pct']\n",
    "    games_by_team_visitor['opponent_tov_pct'] = game['h_ff_tov_pct']\n",
    "    games_by_team_visitor['opponent_ft_rate'] = game['h_ff_ft_rate']\n",
    "    games_by_team_visitor['opponent_off_rtg'] = game['h_ff_off_rtg']\n",
    "\n",
    "    games_by_team_visitor['is_win'] = ''\n",
    "    for i in range(len(game)):\n",
    "        games_by_team_visitor.loc[i,'is_win'] = 1 if game['home_spread'][i].astype(int) < 0 else 0\n",
    "\n",
    "    games_by_team = pd.concat([games_by_team_home,games_by_team_visitor])\n",
    "    games_by_team.set_index('game_key', inplace=True)\n",
    "\n",
    "    del games_by_team_visitor\n",
    "    del games_by_team_home\n",
    "    \n",
    "    ## Create player variables needed for model\n",
    "    # Make game key unique per home/away team\n",
    "    player['game_key'] = player['game_key'] + player['h_or_a']\n",
    "\n",
    "    #Only include players that actually played\n",
    "    player = player.dropna(subset=['mp', 'plus_minus']).reset_index(drop=True)\n",
    "\n",
    "    player['plus_minus'] = player['plus_minus'].astype(int)\n",
    "    player['seconds_played'] = player['mp'].apply(convert_to_seconds)\n",
    "\n",
    "    ## Create dataframe for aggregated player stats per game\n",
    "    game_player_stats = pd.DataFrame()\n",
    "    game_player_stats['game_key'] = player['game_key'].unique()\n",
    "\n",
    "    total_seconds = player.groupby(['game_key'])['seconds_played'].sum()\n",
    "    starter_seconds = player[player['starter_flag']==True].groupby(['game_key'])['seconds_played'].sum()\n",
    "    seconds = pd.merge(total_seconds, starter_seconds, left_index=True, right_index=True, how='inner')\n",
    "    seconds['starter_minutes_played_proportion'] = seconds['seconds_played_y']/seconds['seconds_played_x']\n",
    "\n",
    "    game_player_stats.set_index('game_key',inplace=True)\n",
    "    game_player_stats = pd.merge(game_player_stats,seconds['starter_minutes_played_proportion'],left_index=True,right_index=True,how='inner')\n",
    "\n",
    "    bench_pl_min = player[player['starter_flag']==False].groupby(['game_key'])['plus_minus'].sum()\n",
    "    game_player_stats = pd.merge(game_player_stats,bench_pl_min, left_index=True, right_index=True, how='inner')\n",
    "    game_player_stats = game_player_stats.rename(columns={'plus_minus':'bench_plus_minus'})\n",
    "\n",
    "    ## Merge aggregated stats in to games by team dataframe\n",
    "    games_by_team = pd.merge(games_by_team,game_player_stats, left_index=True, right_index=True,how='inner')\n",
    "    \n",
    "    ## Create dataframe to capture opponent aggregated stats\n",
    "    game_player_stats_opponent = game_player_stats.copy()\n",
    "    \n",
    "    del game_player_stats\n",
    "    \n",
    "    # Reset index so it can be modified to temporarily swith 'h' with 'a'\n",
    "    game_player_stats_opponent.reset_index(drop=False, inplace=True)\n",
    "    game_player_stats_opponent['game_key'] = game_player_stats_opponent['game_key'].apply(switch_key)\n",
    "\n",
    "    #Rename columns to opponent columns\n",
    "    game_player_stats_opponent = game_player_stats_opponent.rename(columns={'starter_minutes_played_proportion':'opponnent_starter_minutes_played_proportion','bench_plus_minus':'opponent_bench_plus_minus'})\n",
    "\n",
    "    #Reset index and merge\n",
    "    game_player_stats_opponent.set_index('game_key', inplace=True)\n",
    "    games_by_team = pd.merge(games_by_team,game_player_stats_opponent,left_index=True,right_index=True,how='inner')\n",
    "\n",
    "    del game_player_stats_opponent\n",
    "\n",
    "    #Create data frame with stats needed for model\n",
    "    for team in games_by_team['team'].unique():\n",
    "        team_games = games_by_team.loc[games_by_team['team']==team].sort_values(by='game_date')\n",
    "        team_games = generate_streak_info(team_games,'is_win')\n",
    "        team_games['streak_counter_is_win'] = [x * -1 if y == 0 else x for x,y in zip(team_games['streak_counter_is_win'],team_games['is_win'])]\n",
    "        team_games['incoming_is_win_streak'] = team_games['streak_counter_is_win'].shift()\n",
    "        for col in wma_columns:\n",
    "            team_games = create_linear_weighted_moving_average(team_games,col,W)\n",
    "            team_games[f'incoming_wma_{W}_{col}'] = team_games[f'wma_{W}_{col}'].shift()\n",
    "        games_by_team = pd.concat([games_by_team, team_games])\n",
    "\n",
    "    #Drop first W rows for each team with no incoming weighted average\n",
    "    model_game_data = games_by_team.dropna(subset=['incoming_wma_10_pace'])\n",
    "\n",
    "    del games_by_team\n",
    "    \n",
    "    #Convert data types to prepare for load to bigquery\n",
    "    model_game_data = model_game_data.astype({'season':int, 'is_win':int})\n",
    "    \n",
    "    #Reset index to load game_date\n",
    "    model_game_data.reset_index(drop=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bottom-punishment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_game_data.duplicated(keep=False).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "shaped-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Index.unique of Index(['Vancouver Grizzlies', 'New Orleans/Oklahoma City Hornets',\n",
       "       'Seattle SuperSonics', 'New Jersey Nets', 'New Orleans Hornets',\n",
       "       'Charlotte Bobcats', 'Cleveland Cavaliers', 'Minnesota Timberwolves',\n",
       "       'San Antonio Spurs', 'Orlando Magic', 'Washington Wizards',\n",
       "       'Dallas Mavericks', 'New York Knicks', 'Denver Nuggets',\n",
       "       'Brooklyn Nets', 'Philadelphia 76ers', 'New Orleans Pelicans',\n",
       "       'Milwaukee Bucks', 'Charlotte Hornets', 'Golden State Warriors',\n",
       "       'Houston Rockets', 'Indiana Pacers', 'Sacramento Kings',\n",
       "       'Los Angeles Clippers', 'Los Angeles Lakers', 'Oklahoma City Thunder',\n",
       "       'Memphis Grizzlies', 'Boston Celtics', 'Toronto Raptors', 'Miami Heat',\n",
       "       'Chicago Bulls', 'Utah Jazz', 'Detroit Pistons', 'Phoenix Suns',\n",
       "       'Atlanta Hawks', 'Portland Trail Blazers'],\n",
       "      dtype='object', name='team')>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent_game.index.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dangerous-merit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vancouver Grizzlies\n",
      "New Orleans\\Oklahoma City Hornets\n",
      "Seattle SuperSonics\n",
      "New Jersey Nets\n",
      "New Orleans Hornets\n",
      "Charlotte Bobcats\n",
      "Cleveland Cavaliers\n",
      "Minnesota Timberwolves\n",
      "San Antonio Spurs\n",
      "Orlando Magic\n",
      "Washington Wizards\n",
      "Dallas Mavericks\n",
      "New York Knicks\n",
      "Denver Nuggets\n",
      "Brooklyn Nets\n",
      "Philadelphia 76ers\n",
      "New Orleans Pelicans\n",
      "Milwaukee Bucks\n",
      "Charlotte Hornets\n",
      "Golden State Warriors\n",
      "Houston Rockets\n",
      "Indiana Pacers\n",
      "Sacramento Kings\n",
      "Los Angeles Clippers\n",
      "Los Angeles Lakers\n",
      "Oklahoma City Thunder\n",
      "Memphis Grizzlies\n",
      "Boston Celtics\n",
      "Toronto Raptors\n",
      "Miami Heat\n",
      "Chicago Bulls\n",
      "Utah Jazz\n",
      "Detroit Pistons\n",
      "Phoenix Suns\n",
      "Atlanta Hawks\n",
      "Portland Trail Blazers\n"
     ]
    }
   ],
   "source": [
    "for team in most_recent_game.index.unique():\n",
    "    team = team.replace('/','\\\\')\n",
    "    print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "utility-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_game = model_game_data.sort_values('game_date').drop_duplicates(['team'],keep='last')\n",
    "most_recent_game = most_recent_game[['season', 'game_date', 'team','streak_counter_is_win',\n",
    "       'wma_10_pace', 'wma_10_efg_pct', 'wma_10_tov_pct', 'wma_10_ft_rate',\n",
    "       'wma_10_off_rtg', 'wma_10_opponent_efg_pct', 'wma_10_opponent_tov_pct',\n",
    "       'wma_10_opponent_ft_rate', 'wma_10_opponent_off_rtg',\n",
    "       'wma_10_starter_minutes_played_proportion', 'wma_10_bench_plus_minus',\n",
    "       'wma_10_opponnent_starter_minutes_played_proportion',\n",
    "       'wma_10_opponent_bench_plus_minus']]\n",
    "most_recent_game.reset_index(drop=True, inplace=True)\n",
    "most_recent_game.set_index('team', inplace=True)\n",
    "docs = most_recent_game.to_dict(orient='index')\n",
    "#firebase_admin.initialize_app()\n",
    "db = firestore.client()\n",
    "for team in most_recent_game.index.unique():\n",
    "    doc_ref = db.collection('team_model_data').document(team.replace('/','\\\\')) #Teams that changed mid-season have a '/' which firestore interprets as new path\n",
    "    doc_ref.set(docs[team])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-virus",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-8-ad6c57dd2518>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-ad6c57dd2518>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    return model_message\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "    #Create new client and load table to Big Query\n",
    "    bqclient = bigquery.Client(project=my_project_id)\n",
    "    #Publish model data\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.autodetect='True'\n",
    "    job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "    job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "        type_=bigquery.TimePartitioningType.DAY,\n",
    "        field=\"game_date\")\n",
    "    ## Set schema for specific columns where more information is needed (e.g. not NULLABLE or specific date/time)\n",
    "    job_config.schema = [\n",
    "        bigquery.SchemaField('game_key','STRING', 'REQUIRED'),\n",
    "        bigquery.SchemaField('team','STRING', 'REQUIRED'),\n",
    "        bigquery.SchemaField('opponent','STRING', 'REQUIRED'),\n",
    "        bigquery.SchemaField('game_date','DATE'),\n",
    "    ]\n",
    "    job_model = bqclient.load_table_from_dataframe(model_game_data, model_table_name, job_config=job_config)\n",
    "\n",
    "    model_result = job_model.result()\n",
    "    model_message = (\n",
    "        f'Job ID: {model_result.job_id} '\n",
    "        f'was started {model_result.started} '\n",
    "        f'and ended {model_result.ended} '\n",
    "        f'loading {model_result.output_rows} row(s) '\n",
    "        f'to {model_result.destination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "personal-series",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "olympic-retro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "english-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "import firebase_admin\n",
    "from firebase_admin import firestore\n",
    "import os\n",
    "\n",
    "## Insert initial setup in entry point function: create_model_data\n",
    "\n",
    "def convert_to_seconds(x):\n",
    "    sp = int(x.split(':')[0]) * 60 + int(x.split(':')[1])\n",
    "    return sp\n",
    "\n",
    "def switch_key(key):\n",
    "    new_key = key[:-1] + ('h' if key[-1] == 'a' else 'a')\n",
    "    return new_key\n",
    "\n",
    "def generate_streak_info(data,column):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate streak data\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate streak info\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_streak_counter:\n",
    "        The original dataframe with a new column\n",
    "        `streak_counter_[column]` containing integers with \n",
    "        counts for each streak.\n",
    "    \"\"\"\n",
    "    \n",
    "    data['start_of_streak'] = data[column].ne(data[column].shift())\n",
    "    data['streak_id'] = data.start_of_streak.cumsum()\n",
    "    data[f'streak_counter_{column}'] = data.groupby('streak_id').cumcount() + 1\n",
    "    data_with_streak_counter = data.drop(columns = ['start_of_streak','streak_id'] )\n",
    "    return data_with_streak_counter\n",
    "\n",
    "def create_linear_weighted_moving_average(data,column,W):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate weighted moving average.\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate weighted moving average info.\n",
    "      Column must be ready to be converted to float data type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_moving_average:\n",
    "        The original dataframe with a new column\n",
    "        `wma_[W]_[column]` containing float values with weighted moving average\n",
    "        values for the provided value with a weight of W.\n",
    "    \"\"\"  \n",
    "    data_with_moving_average = data.copy()\n",
    "    data_with_moving_average[column] = data_with_moving_average[column].astype(float)\n",
    "    weights = np.arange(1,W+1)\n",
    "    data_with_moving_average[f'wma_{W}_{column}'] = data_with_moving_average[column].rolling(W).apply(lambda col: np.dot(col, weights)/weights.sum(), raw=True)\n",
    "    return data_with_moving_average\n",
    "\n",
    "def create_model_data(request):\n",
    "    \n",
    " \n",
    "    request_json = request\n",
    "    if request_json:\n",
    "        print(\"Payload ignored. This function does not use a payload\")\n",
    "    \n",
    "    \n",
    "    ## Setup\n",
    "    my_project_id = os.environ.get('GCP_PROJECT')\n",
    "    client = bigquery.Client(project=my_project_id)\n",
    "    raw_game_data_table = 'nba.raw_basketballreference_game'\n",
    "    raw_player_data_table = 'nba.raw_basketballreference_playerbox'\n",
    "    model_table_name = 'nba.model_game'\n",
    "\n",
    "    # Enter columns to created linearly weighted moving average calculations and number of periods to use\n",
    "    wma_columns = ['pace',\n",
    "        'efg_pct', 'tov_pct', 'ft_rate', 'off_rtg',\n",
    "        'opponent_efg_pct', 'opponent_tov_pct', 'opponent_ft_rate',\n",
    "        'opponent_off_rtg', 'starter_minutes_played_proportion',\n",
    "        'bench_plus_minus', 'opponnent_starter_minutes_played_proportion',\n",
    "        'opponent_bench_plus_minus']\n",
    "    W = 10\n",
    "    \n",
    "    ## Load tables to dataframe\n",
    "    game = client.query('''\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `%s`\n",
    "    ''' % (raw_game_data_table)).to_dataframe()\n",
    "\n",
    "    player = client.query('''\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `%s`\n",
    "    ''' % (raw_player_data_table)).to_dataframe()\n",
    "\n",
    "    ## Create game variables needed for model\n",
    "    game['home_spread'] = game['home_pts'].astype(int) - game['visitor_pts'].astype(int)\n",
    "    game['season'] = ''\n",
    "    for i in range(len(game)):\n",
    "        if ((game['game_date'][i].year != 2020 and game['game_date'][i].month < 7) or (game['game_date'][i].year == 2020 and game['game_date'][i].month < 11)):\n",
    "            game.loc[i,'season'] = game['game_date'][i].year\n",
    "        else:\n",
    "            game.loc[i,'season'] = game['game_date'][i].year + 1\n",
    "\n",
    "\n",
    "    ## Create game by team variables - stack home and away to team vs. opponent\n",
    "    games_by_team_home = pd.DataFrame()\n",
    "    games_by_team_home['season'] = game['season']\n",
    "    games_by_team_home['game_key'] = game['game_key'] + 'h'\n",
    "    games_by_team_home['game_date'] = pd.to_datetime(game['game_date'])\n",
    "    games_by_team_home['team'] = game['home_team_name']\n",
    "    games_by_team_home['opponent'] = game['visitor_team_name']\n",
    "    games_by_team_home['is_home_team'] = 1\n",
    "    games_by_team_home['spread'] = game['home_spread']\n",
    "    games_by_team_home['pace'] = game['h_ff_pace']\n",
    "    games_by_team_home['efg_pct'] = game['h_ff_efg_pct']\n",
    "    games_by_team_home['tov_pct'] = game['h_ff_tov_pct']\n",
    "    games_by_team_home['ft_rate'] = game['h_ff_ft_rate']\n",
    "    games_by_team_home['off_rtg'] = game['h_ff_off_rtg']\n",
    "    games_by_team_home['opponent_efg_pct'] = game['a_ff_efg_pct']\n",
    "    games_by_team_home['opponent_tov_pct'] = game['a_ff_tov_pct']\n",
    "    games_by_team_home['opponent_ft_rate'] = game['a_ff_ft_rate']\n",
    "    games_by_team_home['opponent_off_rtg'] = game['a_ff_off_rtg']\n",
    "\n",
    "\n",
    "    games_by_team_home['is_win'] = ''\n",
    "    for i in range(len(game)):\n",
    "        games_by_team_home.loc[i,'is_win'] = 1 if game['home_spread'][i].astype(int) > 0 else 0\n",
    "\n",
    "\n",
    "    games_by_team_visitor = pd.DataFrame()\n",
    "    games_by_team_visitor ['season'] = game['season']\n",
    "    games_by_team_visitor ['game_key'] = game['game_key'] + 'a'\n",
    "    games_by_team_visitor ['game_date'] = pd.to_datetime(game['game_date'])\n",
    "    games_by_team_visitor ['team'] = game['visitor_team_name']\n",
    "    games_by_team_visitor ['opponent'] = game['home_team_name']\n",
    "    games_by_team_visitor ['is_home_team'] = 0\n",
    "    games_by_team_visitor ['spread'] = game['home_spread']*-1\n",
    "    games_by_team_visitor ['pace'] = game['a_ff_pace']\n",
    "    games_by_team_visitor ['efg_pct'] = game['a_ff_efg_pct']\n",
    "    games_by_team_visitor ['tov_pct'] = game['a_ff_tov_pct']\n",
    "    games_by_team_visitor ['ft_rate'] = game['a_ff_ft_rate']\n",
    "    games_by_team_visitor ['off_rtg'] = game['a_ff_off_rtg']\n",
    "    games_by_team_visitor['opponent_efg_pct'] = game['h_ff_efg_pct']\n",
    "    games_by_team_visitor['opponent_tov_pct'] = game['h_ff_tov_pct']\n",
    "    games_by_team_visitor['opponent_ft_rate'] = game['h_ff_ft_rate']\n",
    "    games_by_team_visitor['opponent_off_rtg'] = game['h_ff_off_rtg']\n",
    "\n",
    "    games_by_team_visitor['is_win'] = ''\n",
    "    for i in range(len(game)):\n",
    "        games_by_team_visitor.loc[i,'is_win'] = 1 if game['home_spread'][i].astype(int) < 0 else 0\n",
    "\n",
    "    games_by_team = pd.concat([games_by_team_home,games_by_team_visitor])\n",
    "    games_by_team.set_index('game_key', inplace=True)\n",
    "\n",
    "    del games_by_team_visitor\n",
    "    del games_by_team_home\n",
    "    \n",
    "    ## Create player variables needed for model\n",
    "    # Make game key unique per home/away team\n",
    "    player['game_key'] = player['game_key'] + player['h_or_a']\n",
    "\n",
    "    #Only include players that actually played\n",
    "    player = player.dropna(subset=['mp', 'plus_minus']).reset_index(drop=True)\n",
    "\n",
    "    player['plus_minus'] = player['plus_minus'].astype(int)\n",
    "    player['seconds_played'] = player['mp'].apply(convert_to_seconds)\n",
    "\n",
    "    ## Create dataframe for aggregated player stats per game\n",
    "    game_player_stats = pd.DataFrame()\n",
    "    game_player_stats['game_key'] = player['game_key'].unique()\n",
    "\n",
    "    total_seconds = player.groupby(['game_key'])['seconds_played'].sum()\n",
    "    starter_seconds = player[player['starter_flag']==True].groupby(['game_key'])['seconds_played'].sum()\n",
    "    seconds = pd.merge(total_seconds, starter_seconds, left_index=True, right_index=True, how='inner')\n",
    "    seconds['starter_minutes_played_proportion'] = seconds['seconds_played_y']/seconds['seconds_played_x']\n",
    "\n",
    "    game_player_stats.set_index('game_key',inplace=True)\n",
    "    game_player_stats = pd.merge(game_player_stats,seconds['starter_minutes_played_proportion'],left_index=True,right_index=True,how='inner')\n",
    "\n",
    "    bench_pl_min = player[player['starter_flag']==False].groupby(['game_key'])['plus_minus'].sum()\n",
    "    game_player_stats = pd.merge(game_player_stats,bench_pl_min, left_index=True, right_index=True, how='inner')\n",
    "    game_player_stats = game_player_stats.rename(columns={'plus_minus':'bench_plus_minus'})\n",
    "\n",
    "    ## Merge aggregated stats in to games by team dataframe\n",
    "    games_by_team = pd.merge(games_by_team,game_player_stats, left_index=True, right_index=True,how='inner')\n",
    "    \n",
    "    ## Create dataframe to capture opponent aggregated stats\n",
    "    game_player_stats_opponent = game_player_stats.copy()\n",
    "    \n",
    "    del game_player_stats\n",
    "    \n",
    "    # Reset index so it can be modified to temporarily swith 'h' with 'a'\n",
    "    game_player_stats_opponent.reset_index(drop=False, inplace=True)\n",
    "    game_player_stats_opponent['game_key'] = game_player_stats_opponent['game_key'].apply(switch_key)\n",
    "\n",
    "    #Rename columns to opponent columns\n",
    "    game_player_stats_opponent = game_player_stats_opponent.rename(columns={'starter_minutes_played_proportion':'opponnent_starter_minutes_played_proportion','bench_plus_minus':'opponent_bench_plus_minus'})\n",
    "\n",
    "    #Reset index and merge\n",
    "    game_player_stats_opponent.set_index('game_key', inplace=True)\n",
    "    games_by_team = pd.merge(games_by_team,game_player_stats_opponent,left_index=True,right_index=True,how='inner')\n",
    "\n",
    "    del game_player_stats_opponent\n",
    "\n",
    "    #Create data frame with stats needed for model\n",
    "    for team in games_by_team['team'].unique():\n",
    "        team_games = games_by_team.loc[games_by_team['team']==team].sort_values(by='game_date')\n",
    "        team_games = generate_streak_info(team_games,'is_win')\n",
    "        team_games['streak_counter_is_win'] = [x * -1 if y == 0 else x for x,y in zip(team_games['streak_counter_is_win'],team_games['is_win'])]\n",
    "        team_games['incoming_is_win_streak'] = team_games['streak_counter_is_win'].shift()\n",
    "        for col in wma_columns:\n",
    "            team_games = create_linear_weighted_moving_average(team_games,col,W)\n",
    "            team_games[f'incoming_wma_{W}_{col}'] = team_games[f'wma_{W}_{col}'].shift()\n",
    "        games_by_team = pd.concat([games_by_team, team_games])\n",
    "\n",
    "    #Drop first W rows for each team with no incoming weighted average\n",
    "    model_game_data = games_by_team.dropna(subset=['incoming_wma_10_pace'])\n",
    "\n",
    "    del games_by_team\n",
    "    \n",
    "    #Convert data types to prepare for load to bigquery\n",
    "    model_game_data = model_game_data.astype({'season':int, 'is_win':int})\n",
    "    \n",
    "    #Reset index to load game_date\n",
    "    model_game_data.reset_index(drop=False,inplace=True)\n",
    "\n",
    "    #Create data frame to create firestore collections with data to use in model call\n",
    "    most_recent_game = model_game_data.sort_values('game_date').drop_duplicates(['team'],keep='last')\n",
    "    most_recent_game = most_recent_game[['season', 'game_date', 'team','streak_counter_is_win',\n",
    "        'wma_10_pace', 'wma_10_efg_pct', 'wma_10_tov_pct', 'wma_10_ft_rate',\n",
    "        'wma_10_off_rtg', 'wma_10_opponent_efg_pct', 'wma_10_opponent_tov_pct',\n",
    "        'wma_10_opponent_ft_rate', 'wma_10_opponent_off_rtg',\n",
    "        'wma_10_starter_minutes_played_proportion', 'wma_10_bench_plus_minus',\n",
    "        'wma_10_opponnent_starter_minutes_played_proportion',\n",
    "        'wma_10_opponent_bench_plus_minus']]\n",
    "    most_recent_game.reset_index(drop=True, inplace=True)\n",
    "    most_recent_game.set_index('team', inplace=True)\n",
    "    docs = most_recent_game.to_dict(orient='index')\n",
    "    #firebase_admin.initialize_app()\n",
    "    db = firestore.client()\n",
    "    for team in most_recent_game.index.unique():\n",
    "        doc_ref = db.collection('team_model_data').document(team.replace('/','\\\\')) #Teams that changed mid-season have a '/' which firestore interprets as new path\n",
    "        doc_ref.set(docs[team])\n",
    "    \n",
    "    del most_recent_game\n",
    "\n",
    "    #Create new client and load model table to Big Query\n",
    "    bqclient = bigquery.Client(project=my_project_id)\n",
    "    #Publish model data\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.autodetect='True'\n",
    "    job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "    job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "#     job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "#         type_=bigquery.TimePartitioningType.DAY,\n",
    "#         field=\"game_date\")\n",
    "    ## Set schema for specific columns where more information is needed (e.g. not NULLABLE or specific date/time)\n",
    "    job_config.schema = [\n",
    "        bigquery.SchemaField('game_key','STRING', 'REQUIRED'),\n",
    "        bigquery.SchemaField('team','STRING', 'REQUIRED'),\n",
    "        bigquery.SchemaField('opponent','STRING', 'REQUIRED'),\n",
    "        bigquery.SchemaField('game_date','DATE'),\n",
    "    ]\n",
    "    job_model = bqclient.load_table_from_dataframe(model_game_data, model_table_name, job_config=job_config)\n",
    "\n",
    "    model_result = job_model.result()\n",
    "    model_message = (\n",
    "        f'Job ID: {model_result.job_id} '\n",
    "        f'was started {model_result.started} '\n",
    "        f'and ended {model_result.ended} '\n",
    "        f'loading {model_result.output_rows} row(s) '\n",
    "        f'to {model_result.destination}')\n",
    "\n",
    "    return model_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "incorrect-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload ignored. This function does not use a payload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Job ID: e4654ddf-e349-47ad-9f65-069b6132cc89 was started 2021-02-28 07:22:31.218000+00:00 and ended 2021-02-28 07:22:34.208000+00:00 loading 54472 row(s) to nba-predictions-dev.nba.model_game'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_data(\"request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
