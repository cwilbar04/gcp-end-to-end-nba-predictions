{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fourth-anthropology",
   "metadata": {},
   "source": [
    "# NBA Model Table Initial Load\n",
    "\n",
    "Run this workbook after you have used the [NBA Data Inital Load](https://github.com/cwilbar04/nba-predictions/blob/dev/notebooks/NBA%20Data%20Initial%20Load.ipynb) workbook to create and load the modeled data used for analysis that combines and enhances the raw game and player data.\n",
    "\n",
    "Prerequisites:\n",
    "- Complete steps 1-6 in the [Project Creation Workbook](https://github.com/cwilbar04/nba-predictions/blob/main/notebooks/Project%20Creation%20Workbook.ipynb)\n",
    "- Complete part 1 of Step 7 by running [NBA Data Inital Load](https://github.com/cwilbar04/nba-predictions/blob/dev/notebooks/NBA%20Data%20Initial%20Load.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technological-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this function locally after initial data load since it will take more memory than google cloud functions allows\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import firestore\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legislative-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO: Replace your Project ID and change the table names if you chose a different dataset name than 'nba' ##\n",
    "\n",
    "os.environ['GCP_PROJECT'] = 'nba-predictions-prod'\n",
    "my_project_id = os.environ.get('GCP_PROJECT')\n",
    "client = bigquery.Client(project=my_project_id)\n",
    "raw_game_data_table = f'{my_project_id}.nba.raw_basketballreference_game'\n",
    "raw_player_data_table = f'{my_project_id}.nba.raw_basketballreference_playerbox'\n",
    "games_to_load_to_model_view = f'{my_project_id}.nba.games_to_load_to_model'\n",
    "model_table_name = f'{my_project_id}.nba.model_game'\n",
    "\n",
    "# Enter columns you want to generate linearly weighted moving average calculations for and number of periods to use\n",
    "wma_columns = ['pace',\n",
    "    'efg_pct', 'tov_pct', 'ft_rate', 'off_rtg',\n",
    "    'opponent_efg_pct', 'opponent_tov_pct', 'opponent_ft_rate',\n",
    "    'opponent_off_rtg', 'starter_minutes_played_proportion',\n",
    "    'bench_plus_minus', 'opponnent_starter_minutes_played_proportion',\n",
    "    'opponent_bench_plus_minus']\n",
    "W = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guilty-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 860e829b-71bd-4590-bd74-ba313707963a was started 2021-03-11 06:25:40.500000+00:00 and ended 2021-03-11 06:25:44.362000+00:00 loading 54206 row(s) to nba-predictions-prod.nba.model_game\n"
     ]
    }
   ],
   "source": [
    "def convert_to_seconds(x):\n",
    "    sp = int(x.split(':')[0]) * 60 + int(x.split(':')[1])\n",
    "    return sp\n",
    "\n",
    "def switch_key(key):\n",
    "    new_key = key[:-1] + ('h' if key[-1] == 'a' else 'a')\n",
    "    return new_key\n",
    "\n",
    "def generate_streak_info(data,column):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate streak data\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate streak info\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_streak_counter:\n",
    "        The original dataframe with a new column\n",
    "        `streak_counter_[column]` containing integers with \n",
    "        counts for each streak.\n",
    "    \"\"\"\n",
    "    \n",
    "    data['start_of_streak'] = data[column].ne(data[column].shift())\n",
    "    data['streak_id'] = data.start_of_streak.cumsum()\n",
    "    data[f'streak_counter_{column}'] = data.groupby('streak_id').cumcount() + 1\n",
    "    data_with_streak_counter = data.drop(columns = ['start_of_streak','streak_id'] )\n",
    "    return data_with_streak_counter\n",
    "\n",
    "def create_linear_weighted_moving_average(data,column,weight):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data:\n",
    "      Dataframe with a specific column to generate weighted moving average.\n",
    "\n",
    "    column:\n",
    "      Stirng with specific column name to generate weighted moving average info.\n",
    "      Column must be ready to be converted to float data type.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    data_with_moving_average:\n",
    "        The original dataframe with a new column\n",
    "        `wma_[W]_[column]` containing float values with weighted moving average\n",
    "        values for the provided value with a weight of W.\n",
    "    \"\"\"  \n",
    "    data_with_moving_average = data.copy()\n",
    "    data_with_moving_average[column] = data_with_moving_average[column].astype(float)\n",
    "    weights = np.arange(1,weight+1)\n",
    "    data_with_moving_average[f'wma_{weight}_{column}'] = data_with_moving_average[column].rolling(weight).apply(lambda col: np.dot(col, weights)/weights.sum(), raw=True)\n",
    "    return data_with_moving_average\n",
    "\n",
    "## Load tables to dataframe\n",
    "game_bq = client.query('''\n",
    "SELECT game_date, visitor_team_name, visitor_pts, home_team_name, home_pts, games.game_key, \n",
    "    a_ff_pace, a_ff_efg_pct, a_ff_tov_pct, a_ff_orb_pct, a_ff_ft_rate, a_ff_off_rtg, \n",
    "    h_ff_pace, h_ff_efg_pct, h_ff_tov_pct,h_ff_orb_pct, h_ff_ft_rate, h_ff_off_rtg\n",
    "FROM `%s` as games\n",
    "''' % (raw_game_data_table)).to_dataframe()\n",
    "\n",
    "if game_bq.empty:\n",
    "    print('Function ended early. No new data to load.')\n",
    "\n",
    "player_bq = client.query('''\n",
    "SELECT players.game_key, game_date, h_or_a, mp, plus_minus, starter_flag\n",
    "FROM `%s` as players\n",
    "WHERE mp is not NULL\n",
    "''' % (raw_player_data_table)).to_dataframe()\n",
    "\n",
    "## Create copies to avoid calling bigquery multiple times when testing - comment out delete while testing\n",
    "game = game_bq.copy()\n",
    "player = player_bq.copy()\n",
    "\n",
    "del game_bq\n",
    "del player_bq\n",
    "\n",
    "## Create game variables needed for model\n",
    "game['home_spread'] = game['home_pts'].astype(int) - game['visitor_pts'].astype(int)\n",
    "game['season'] = ''\n",
    "for i in range(len(game)):\n",
    "    if ((game['game_date'][i].year != 2020 and game['game_date'][i].month < 7) or (game['game_date'][i].year == 2020 and game['game_date'][i].month < 11)):\n",
    "        game.loc[i,'season'] = game['game_date'][i].year\n",
    "    else:\n",
    "        game.loc[i,'season'] = game['game_date'][i].year + 1\n",
    "\n",
    "\n",
    "## Create game by team variables - stack home and away to team vs. opponent\n",
    "games_by_team_home = pd.DataFrame()\n",
    "games_by_team_home['season'] = game['season']\n",
    "games_by_team_home['game_key'] = game['game_key']\n",
    "games_by_team_home['game_key_team'] = game['game_key'] + 'h'\n",
    "games_by_team_home['game_key_opponent'] = game['game_key'] + 'a'\n",
    "games_by_team_home['game_date'] = pd.to_datetime(game['game_date'])\n",
    "games_by_team_home['team'] = game['home_team_name']\n",
    "games_by_team_home['opponent'] = game['visitor_team_name']\n",
    "games_by_team_home['is_home_team'] = 1\n",
    "games_by_team_home['spread'] = game['home_spread']\n",
    "games_by_team_home['pace'] = game['h_ff_pace']\n",
    "games_by_team_home['efg_pct'] = game['h_ff_efg_pct']\n",
    "games_by_team_home['tov_pct'] = game['h_ff_tov_pct']\n",
    "games_by_team_home['ft_rate'] = game['h_ff_ft_rate']\n",
    "games_by_team_home['off_rtg'] = game['h_ff_off_rtg']\n",
    "games_by_team_home['opponent_efg_pct'] = game['a_ff_efg_pct']\n",
    "games_by_team_home['opponent_tov_pct'] = game['a_ff_tov_pct']\n",
    "games_by_team_home['opponent_ft_rate'] = game['a_ff_ft_rate']\n",
    "games_by_team_home['opponent_off_rtg'] = game['a_ff_off_rtg']\n",
    "games_by_team_home['is_win'] = [1 if x > 0 else 0 for x in games_by_team_home['spread'].astype(int)]\n",
    "\n",
    "\n",
    "games_by_team_visitor = pd.DataFrame()\n",
    "games_by_team_visitor ['season'] = game['season']\n",
    "games_by_team_visitor['game_key'] = game['game_key']\n",
    "games_by_team_visitor ['game_key_team'] = game['game_key'] + 'a'\n",
    "games_by_team_visitor ['game_key_opponent'] = game['game_key'] + 'h'\n",
    "games_by_team_visitor ['game_date'] = pd.to_datetime(game['game_date'])\n",
    "games_by_team_visitor ['team'] = game['visitor_team_name']\n",
    "games_by_team_visitor ['opponent'] = game['home_team_name']\n",
    "games_by_team_visitor ['is_home_team'] = 0\n",
    "games_by_team_visitor ['spread'] = game['home_spread']*-1\n",
    "games_by_team_visitor ['pace'] = game['a_ff_pace']\n",
    "games_by_team_visitor ['efg_pct'] = game['a_ff_efg_pct']\n",
    "games_by_team_visitor ['tov_pct'] = game['a_ff_tov_pct']\n",
    "games_by_team_visitor ['ft_rate'] = game['a_ff_ft_rate']\n",
    "games_by_team_visitor ['off_rtg'] = game['a_ff_off_rtg']\n",
    "games_by_team_visitor['opponent_efg_pct'] = game['h_ff_efg_pct']\n",
    "games_by_team_visitor['opponent_tov_pct'] = game['h_ff_tov_pct']\n",
    "games_by_team_visitor['opponent_ft_rate'] = game['h_ff_ft_rate']\n",
    "games_by_team_visitor['opponent_off_rtg'] = game['h_ff_off_rtg']\n",
    "games_by_team_visitor['is_win'] = [1 if x > 0 else 0 for x in games_by_team_visitor['spread'].astype(int)]\n",
    "\n",
    "games_by_team = pd.concat([games_by_team_home,games_by_team_visitor])\n",
    "\n",
    "games_by_team.sort_values(by=['game_date'], ascending = True, inplace=True)\n",
    "\n",
    "games_by_team['previous_game_date'] = games_by_team.groupby(['team'])['game_date'].shift(1)\n",
    "\n",
    "games_by_team['incoming_rest_days'] = [(d - p).days for d,p in zip(games_by_team['game_date'],games_by_team['previous_game_date'])] \n",
    "\n",
    "# Replace NaN with -99 so can be converted to int. These rows will be dropped later.\n",
    "games_by_team['incoming_rest_days'].fillna(-99, inplace=True)\n",
    "\n",
    "games_by_team['incoming_rest_days'] = games_by_team['incoming_rest_days'].astype(int)\n",
    "\n",
    "games_by_team.set_index('game_key_team', inplace=True)\n",
    "\n",
    "del games_by_team_visitor\n",
    "del games_by_team_home\n",
    "\n",
    "## Create player variables needed for model\n",
    "# Make game key unique per home/away team\n",
    "player['game_key_team'] = player['game_key'] + player['h_or_a']\n",
    "\n",
    "#Only include players that actually played\n",
    "player = player.dropna(subset=['mp', 'plus_minus']).reset_index(drop=True)\n",
    "\n",
    "player['plus_minus'] = player['plus_minus'].astype(int)\n",
    "player['seconds_played'] = player['mp'].apply(convert_to_seconds)\n",
    "\n",
    "## Create dataframe for aggregated player stats per game\n",
    "game_player_stats = pd.DataFrame()\n",
    "game_player_stats['game_key_team'] = player['game_key_team'].unique()\n",
    "\n",
    "total_seconds = player.groupby(['game_key_team'])['seconds_played'].sum()\n",
    "starter_seconds = player[player['starter_flag']==True].groupby(['game_key_team'])['seconds_played'].sum()\n",
    "seconds = pd.merge(total_seconds, starter_seconds, left_index=True, right_index=True, how='inner')\n",
    "seconds['starter_minutes_played_proportion'] = seconds['seconds_played_y']/seconds['seconds_played_x']\n",
    "\n",
    "game_player_stats.set_index('game_key_team',inplace=True)\n",
    "game_player_stats = pd.merge(game_player_stats,seconds['starter_minutes_played_proportion'],left_index=True,right_index=True,how='inner')\n",
    "\n",
    "bench_pl_min = player[player['starter_flag']==False].groupby(['game_key_team'])['plus_minus'].sum()\n",
    "game_player_stats = pd.merge(game_player_stats,bench_pl_min, left_index=True, right_index=True, how='inner')\n",
    "game_player_stats = game_player_stats.rename(columns={'plus_minus':'bench_plus_minus'})\n",
    "\n",
    "## Merge aggregated stats in to games by team dataframe\n",
    "games_by_team = pd.merge(games_by_team,game_player_stats, left_index=True, right_index=True,how='inner')\n",
    "\n",
    "## Create dataframe to capture opponent aggregated stats\n",
    "game_player_stats_opponent = game_player_stats.copy()\n",
    "\n",
    "del game_player_stats\n",
    "\n",
    "# Reset index so it can be modified to temporarily swith 'h' with 'a'\n",
    "game_player_stats_opponent.reset_index(drop=False, inplace=True)\n",
    "game_player_stats_opponent['game_key_team'] = game_player_stats_opponent['game_key_team'].apply(switch_key)\n",
    "\n",
    "#Rename columns to opponent columns\n",
    "game_player_stats_opponent = game_player_stats_opponent.rename(columns={'starter_minutes_played_proportion':'opponnent_starter_minutes_played_proportion','bench_plus_minus':'opponent_bench_plus_minus'})\n",
    "\n",
    "#Reset index and merge\n",
    "game_player_stats_opponent.set_index('game_key_team', inplace=True)\n",
    "games_by_team = pd.merge(games_by_team,game_player_stats_opponent,left_index=True,right_index=True,how='inner')\n",
    "\n",
    "del game_player_stats_opponent\n",
    "\n",
    "games_by_team_with_wma = pd.DataFrame()\n",
    "#Create data frame with stats needed for model\n",
    "for team in games_by_team['team'].unique():\n",
    "    team_games = games_by_team.loc[games_by_team['team']==team].sort_values(by='game_date')\n",
    "    team_games = generate_streak_info(team_games,'is_win')\n",
    "    team_games['streak_counter_is_win'] = [x * -1 if y == 0 else x for x,y in zip(team_games['streak_counter_is_win'],team_games['is_win'])]\n",
    "    team_games['incoming_is_win_streak'] = team_games['streak_counter_is_win'].shift(fill_value=0)\n",
    "    for col in wma_columns:\n",
    "        team_games = create_linear_weighted_moving_average(team_games,col,W)\n",
    "        team_games[f'incoming_wma_{W}_{col}'] = team_games[f'wma_{W}_{col}'].shift()\n",
    "    games_by_team_with_wma = pd.concat([games_by_team_with_wma, team_games])\n",
    "\n",
    "games_by_team_with_wma = (games_by_team_with_wma.merge(games_by_team_with_wma.reset_index(drop=False)[[\n",
    "                'game_key_team','incoming_rest_days','streak_counter_is_win','incoming_is_win_streak']],\n",
    "                    left_on='game_key_opponent', right_on='game_key_team',\n",
    "                    how='inner', suffixes=(None, '_opponent'))) \n",
    "\n",
    "#Drop first W rows for each team with no incoming weighted average\n",
    "model_game_data = games_by_team_with_wma.dropna(subset=[f'incoming_wma_{W}_pace']).copy()\n",
    "\n",
    "del games_by_team_with_wma\n",
    "del games_by_team\n",
    "\n",
    "#Convert data types to prepare for load to bigquery\n",
    "model_game_data = model_game_data.astype({'season':int, 'is_win':int})\n",
    "\n",
    "#Create data frame to create firestore collections with data to use in model call\n",
    "most_recent_game = model_game_data.sort_values('game_date').drop_duplicates(['team'],keep='last')\n",
    "\n",
    "most_recent_game = most_recent_game[['season', 'game_date', 'team','streak_counter_is_win']\n",
    "                                                     + [f'wma_{W}_{x}' for x in wma_columns]]\n",
    "most_recent_game.reset_index(drop=True, inplace=True)\n",
    "most_recent_game.set_index('team', inplace=True)\n",
    "docs = most_recent_game.to_dict(orient='index')\n",
    "\n",
    "db = firestore.Client(project=my_project_id)\n",
    "for team in most_recent_game.index.unique():\n",
    "    doc_ref = db.collection('team_model_data').document(team.replace('/','\\\\')) #Teams that changed mid-season have a '/' which firestore interprets as new path\n",
    "    doc_ref.set(docs[team])\n",
    "\n",
    "del most_recent_game\n",
    "\n",
    "#Create new client and load table to Big Query\n",
    "bqclient = bigquery.Client(project=my_project_id)\n",
    "#Publish model data\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect='True'\n",
    "job_config.create_disposition = 'CREATE_IF_NEEDED'\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "# job_config.time_partitioning = bigquery.TimePartitioning(\n",
    "#     type_=bigquery.TimePartitioningType.DAY,\n",
    "#     field=\"game_date\")\n",
    "## Set schema for specific columns where more information is needed (e.g. not NULLABLE or specific date/time)\n",
    "job_config.schema = [\n",
    "    bigquery.SchemaField('game_key','STRING', 'REQUIRED'),\n",
    "    bigquery.SchemaField('team','STRING', 'REQUIRED'),\n",
    "    bigquery.SchemaField('opponent','STRING', 'REQUIRED'),\n",
    "    bigquery.SchemaField('game_date','DATE'),\n",
    "]\n",
    "job_model = bqclient.load_table_from_dataframe(model_game_data, model_table_name, job_config=job_config)\n",
    "\n",
    "model_result = job_model.result()\n",
    "model_message = (\n",
    "    f'Job ID: {model_result.job_id} '\n",
    "    f'was started {model_result.started} '\n",
    "    f'and ended {model_result.ended} '\n",
    "    f'loading {model_result.output_rows} row(s) '\n",
    "    f'to {model_result.destination}')\n",
    "\n",
    "print(model_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-recall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
